
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Welcome to dixi's BLOG. Ad infinitum, ad aeternum progredi.">
      
      
        <meta name="author" content="dixi">
      
      
        <link rel="canonical" href="https://dixilog.github.io/changheji/MLreport/">
      
      
        <link rel="prev" href="../bookReport/%E3%80%8A%E8%BF%9C%E5%A4%A7%E5%89%8D%E7%A8%8B%E3%80%8B%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/">
      
      
        <link rel="next" href="../../ROCOS/">
      
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.10">
    
    
      
        <title>基于卷积神经网络的FashionMNIST分类 - dixi's BLOG</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      

  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M22%2012a10%2010%200%200%201-10%2010A10%2010%200%200%201%202%2012%2010%2010%200%200%201%2012%202a10%2010%200%200%201%2010%2010m-12%206%206-6-6-6-1.4%201.4%204.6%204.6-4.6%204.6z%22/%3E%3C/svg%3E');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../stylesheets/custom.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-WNP42HF8NE"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-WNP42HF8NE",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-WNP42HF8NE",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#fashionmnist" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="dixi&#39;s BLOG" class="md-header__button md-logo" aria-label="dixi's BLOG" data-md-component="logo">
      
  <img src="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/%E4%B8%AA%E4%BA%BA%E5%A4%B4%E5%83%8F_4x.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            dixi's BLOG
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              基于卷积神经网络的FashionMNIST分类
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 20h6v1c0 .55-.45 1-1 1h-4c-.55 0-1-.45-1-1zM19 9c0 2.38-1.19 4.47-3 5.74V17c0 .55-.45 1-1 1H9c-.55 0-1-.45-1-1v-2.26C6.19 13.47 5 11.38 5 9c0-3.87 3.13-7 7-7s7 3.13 7 7m-4.29-.71c-.39-.39-1.03-.39-1.42 0L12 9.59l-1.29-1.3c-.39-.39-1.03-.39-1.42 0s-.39 1.03 0 1.42l1.71 1.7V16h2v-4.59l1.71-1.7c.39-.39.39-1.03 0-1.42"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2C8.13 2 5 5.13 5 9c0 2.38 1.19 4.47 3 5.74V17c0 .55.45 1 1 1h6c.55 0 1-.45 1-1v-2.26c1.81-1.27 3-3.36 3-5.74 0-3.87-3.13-7-7-7m2 11.58V16h-1v-4.59l1.71-1.7c.39-.39.39-1.03 0-1.42s-1.03-.39-1.42 0L12 9.59l-1.29-1.3c-.39-.39-1.03-.39-1.42 0s-.39 1.03 0 1.42l1.71 1.7V16h-1v-2.42C8.23 12.81 7 11.05 7 9c0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.05-1.23 3.81-3 4.58M9 20h6v1c0 .55-.45 1-1 1h-4c-.55 0-1-.45-1-1z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M15.5 12c2.5 0 4.5 2 4.5 4.5 0 .88-.25 1.71-.69 2.4l3.08 3.1L21 23.39l-3.12-3.07c-.69.43-1.51.68-2.38.68-2.5 0-4.5-2-4.5-4.5s2-4.5 4.5-4.5m0 2a2.5 2.5 0 0 0-2.5 2.5 2.5 2.5 0 0 0 2.5 2.5 2.5 2.5 0 0 0 2.5-2.5 2.5 2.5 0 0 0-2.5-2.5M7 15v2h2c.14 1.55.8 2.94 1.81 4H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h14a2 2 0 0 1 2 2v8.03A6.49 6.49 0 0 0 15.5 10c-1.27 0-2.46.37-3.46 1H7v2h3c-.36.6-.66 1.28-.83 2zm10-6V7H7v2z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M15.5 12c2.5 0 4.5 2 4.5 4.5 0 .88-.25 1.71-.69 2.4l3.08 3.1L21 23.39l-3.12-3.07c-.69.43-1.51.68-2.38.68-2.5 0-4.5-2-4.5-4.5s2-4.5 4.5-4.5m0 2a2.5 2.5 0 0 0-2.5 2.5 2.5 2.5 0 0 0 2.5 2.5 2.5 2.5 0 0 0 2.5-2.5 2.5 2.5 0 0 0-2.5-2.5M7 15v2h2c.14 1.55.8 2.94 1.81 4H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h14a2 2 0 0 1 2 2v8.03A6.49 6.49 0 0 0 15.5 10c-1.27 0-2.46.37-3.46 1H7v2h3c-.36.6-.66 1.28-.83 2zm10-6V7H7v2z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6 18V6h2v12zm3.5-6L18 6v12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2m0 16H5V5h14zM17 8.4 13.4 12l3.6 3.6-1.4 1.4-3.6-3.6L8.4 17 7 15.6l3.6-3.6L7 8.4 8.4 7l3.6 3.6L15.6 7z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/dixiLOG/dixiLOG.github.io.git" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    dixiLOG
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../.." class="md-tabs__link">
          
  
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../NBU-NOTEBOOK/" class="md-tabs__link">
          
  
  
    
  
  NBU-NOTEBOOK

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../%E9%9A%8F%E6%89%8B%E8%AE%B0/" class="md-tabs__link">
          
  
  
    
  
  随手记

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  长河集

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../ROCOS/" class="md-tabs__link">
          
  
  
    
  
  NBU_ROCOS

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
  
    
  
  闲言碎语

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="dixi&#39;s BLOG" class="md-nav__button md-logo" aria-label="dixi's BLOG" data-md-component="logo">
      
  <img src="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/%E4%B8%AA%E4%BA%BA%E5%A4%B4%E5%83%8F_4x.png" alt="logo">

    </a>
    dixi's BLOG
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dixiLOG/dixiLOG.github.io.git" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    dixiLOG
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../.." class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../NBU-NOTEBOOK/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    NBU-NOTEBOOK
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../%E9%9A%8F%E6%89%8B%E8%AE%B0/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    随手记
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    长河集
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            长河集
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../bookReport/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    荒唐言
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    基于卷积神经网络的FashionMNIST分类
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    基于卷积神经网络的FashionMNIST分类
    
  </span>
  

      </a>
      
        

  

<nav class="md-nav md-nav--secondary" aria-label="Contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      写在前面
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-is-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      WHAT IS CNN？
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WHAT IS CNN？">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn" class="md-nav__link">
    <span class="md-ellipsis">
      CNN 介绍
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN 介绍">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      CNN的一些基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      工作流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      还有什么？
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn_2" class="md-nav__link">
    <span class="md-ellipsis">
      最简单的CNN分类模型：逐行解析
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-cnn-to-work" class="md-nav__link">
    <span class="md-ellipsis">
      Putting CNN to Work
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Putting CNN to Work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#running" class="md-nav__link">
    <span class="md-ellipsis">
      RUNNING！
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      最后
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      附录
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../ROCOS/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    NBU_ROCOS
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../blog/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    闲言碎语
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary" aria-label="Contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      写在前面
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-is-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      WHAT IS CNN？
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WHAT IS CNN？">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn" class="md-nav__link">
    <span class="md-ellipsis">
      CNN 介绍
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CNN 介绍">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cnn_1" class="md-nav__link">
    <span class="md-ellipsis">
      CNN的一些基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      工作流程
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      还有什么？
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn_2" class="md-nav__link">
    <span class="md-ellipsis">
      最简单的CNN分类模型：逐行解析
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-cnn-to-work" class="md-nav__link">
    <span class="md-ellipsis">
      Putting CNN to Work
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Putting CNN to Work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#running" class="md-nav__link">
    <span class="md-ellipsis">
      RUNNING！
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      最后
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      附录
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<div><h1 id="fashionmnist">基于卷积神经网络的FashionMNIST分类<a class="headerlink" href="#fashionmnist" title="Permanent link">¶</a></h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p> </p>
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约 5883 个字  • <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M392.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6m80.6 120.1c-12.5 12.5-12.5 32.8 0 45.3l89.3 89.4-89.4 89.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l112-112c12.5-12.5 12.5-32.8 0-45.3l-112-112c-12.5-12.5-32.8-12.5-45.3 0zm-306.7 0c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3l112 112c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l89.4-89.4c12.5-12.5 12.5-32.8 0-45.3"></path></svg></span> 582 行代码 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间 40 分钟</p>
<hr>
</div>
<div id="progress-container">
  <div id="progress-bar"></div>
</div>

<h2 id="_1">写在前面<a class="headerlink" href="#_1" title="Permanent link">¶</a></h2>
<p>一直有再探ML的欲望，但一直没啥动力。正好以此次大作业为契机，基于项目督促自己学习</p>
<p>全文分为两个部分：<a href="#what-is-cnn">CNN介绍</a>与<a href="#putting-cnn-to-work">Fashion MNIST分类实战</a></p>
<p>前者除了CNN的一些基本概念说明，还尝试通过逐行代码分析解构基本的机器学习框架</p>
<p>后者则是将理论运用于实践中，但较为粗糙</p>
<hr>
<h2 id="what-is-cnn">WHAT IS CNN？<a class="headerlink" href="#what-is-cnn" title="Permanent link">¶</a></h2>
<p>本节对卷积神经网络（Convolutional Neural Network，CNN），在算法与代码两个层面进行介绍。</p>
<h3 id="cnn">CNN 介绍<a class="headerlink" href="#cnn" title="Permanent link">¶</a></h3>
<p>包括 CNN 基本概念与工作流程。</p>
<hr>
<p>卷积神经网络（CNN）是一种专门用于处理具有网格结构数据（如图像）的深度学习模型。</p>
<p>CNN 的核心思想是通过卷积操作（Convolution Operation）提取图像的局部特征，并通过多层网络结构逐步组合这些特征，最终实现分类、检测等任务。CNN 在计算机视觉领域取得了巨大成功，广泛应用于图像分类（Image Classification）、目标检测（Object Detection）、语义分割（Semantic Segmentation）等任务。</p>
<hr>
<h4 id="cnn_1">CNN的一些基本概念<a class="headerlink" href="#cnn_1" title="Permanent link">¶</a></h4>
<div class="tabbed-set tabbed-alternate" data-tabs="1:4"><input checked id="__tabbed_1_1" name="__tabbed_1" type="radio"><input id="__tabbed_1_2" name="__tabbed_1" type="radio"><input id="__tabbed_1_3" name="__tabbed_1" type="radio"><input id="__tabbed_1_4" name="__tabbed_1" type="radio"><div class="tabbed-labels"><label for="__tabbed_1_1"><strong>局部感受野（Local Receptive Field）</strong></label><label for="__tabbed_1_2"><strong>权值共享（Weight Sharing）</strong></label><label for="__tabbed_1_3"><strong>层次化特征提取（Hierarchical Feature Extraction）</strong></label><label for="__tabbed_1_4"><strong>非线性激活（Non-linear Activation）</strong></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>CNN 通过卷积核（Filter/Kernel）在输入图像上滑动，每次只关注图像的一个局部区域（称为感受野），而不是整个图像。</p>
<p>这种局部连接的方式大大减少了参数量，同时保留了图像的局部特征。</p>
<p>比如，一个 3x3 的卷积核每次只处理输入图像的 3x3 区域。</p>
</div>
<div class="tabbed-block">
<p>卷积核在图像上滑动时，使用的是相同的权重参数。这种权值共享机制进一步减少了模型的参数量，并增强了模型对平移不变性（Translation Invariance）的捕捉能力。这使得无论特征出现在图像的哪个位置，卷积核都能检测到它。</p>
</div>
<div class="tabbed-block">
<p>CNN 通过多层卷积和池化操作，逐步提取从低级到高级的特征。低级特征（如边缘、纹理）在浅层提取，而高级特征（如物体形状、语义信息）在深层提取。</p>
</div>
<div class="tabbed-block">
<p>在卷积操作后，通常会使用非线性激活函数（如 ReLU）引入非线性，使模型能够学习更复杂的特征。常用激活函数有ReLU（Rectified Linear Unit）、LeakyReLU、ELU 等。</p>
</div>
</div>
</div>
<hr>
<h4 id="_2">工作流程<a class="headerlink" href="#_2" title="Permanent link">¶</a></h4>
<p>根据FashionMNIST数据集特点，介绍本实验使用的CNN模型工作流程，结构图<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>见图1。</p>
<p><a class="glightbox" href="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/20250211cnn.svg" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="CNN" src="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/20250211cnn.svg"></a></p>
<p></p><center style="font-size:14px;color:#C0C0C0;">图1 神经网络结构图</center>
<ol>
<li><strong>输入图像（Input Image）</strong>  </li>
</ol>
<ul>
<li>输入图像的尺寸为 <code>1@28x28</code>，表示单通道（灰度）的 28x28 像素图像</li>
</ul>
<ol start="2">
<li><strong>第一层卷积（Convolution 1）</strong></li>
</ol>
<ul>
<li>
<p>使用 32 个卷积核（Filters），每个卷积核的尺寸为 <code>3x3</code>，步长为 1，填充为 1</p>
</li>
<li>
<p>输入图像经过卷积操作后，生成 32 个特征图（Feature Maps），每个特征图的尺寸为 <code>28x28</code></p>
</li>
<li>
<p><strong>输出</strong>：<code>32@28x28</code></p>
</li>
</ul>
<ol start="3">
<li><strong>第一层最大池化（Max-Pool 1）</strong></li>
</ol>
<ul>
<li>
<p>对卷积后的特征图进行最大池化操作（Max Pooling），池化窗口尺寸为 <code>2x2</code>，步长为 2</p>
</li>
<li>
<p>池化操作将特征图的尺寸减半</p>
</li>
<li>
<p><strong>输出</strong>：<code>32@14x14</code></p>
</li>
</ul>
<ol start="4">
<li><strong>第二层卷积（Convolution 2）</strong></li>
</ol>
<ul>
<li>
<p>使用 64 个卷积核，每个卷积核的尺寸为 <code>3x3</code>，步长为 1，填充为 1</p>
</li>
<li>
<p>输入为 <code>32@14x14</code> 的特征图，经过卷积操作后，生成 64 个特征图，每个特征图的尺寸为 <code>14x14</code></p>
</li>
<li>
<p><strong>输出</strong>：<code>64@14x14</code></p>
</li>
</ul>
<ol start="5">
<li><strong>第二层最大池化（Max-Pool 2）</strong></li>
</ol>
<ul>
<li>
<p>对卷积后的特征图进行最大池化操作，池化窗口尺寸为 <code>2x2</code>，步长为 2</p>
</li>
<li>
<p>池化操作将特征图的尺寸减半</p>
</li>
<li>
<p><strong>输出</strong>：<code>64@7x7</code></p>
</li>
</ul>
<ol start="6">
<li><strong>展平（Flatten）</strong>
   - 将池化后的特征图展平为一维向量</li>
</ol>
<ul>
<li>输入为 <code>64@7x7</code>，展平后的向量长度为 <code>64 * 7 * 7 = 3136</code></li>
<li><strong>输出</strong>：<code>1x3136</code></li>
</ul>
<ol start="7">
<li><strong>第一层全连接（Fully Connected Layer 1）</strong>
   - 将展平后的向量输入全连接层，全连接层的输出尺寸为 <code>1x128</code></li>
</ol>
<ul>
<li><strong>输出</strong>：<code>1x128</code></li>
</ul>
<ol start="8">
<li><strong>第二层全连接（Fully Connected Layer 2）</strong></li>
</ol>
<ul>
<li>
<p>将第一层全连接层的输出输入第二层全连接层，输出尺寸为 <code>1x10</code>，表示 10 个类别的概率分布</p>
</li>
<li>
<p><strong>输出</strong>：<code>1x10</code></p>
</li>
</ul>
<hr>
<h4 id="_3">还有什么？<a class="headerlink" href="#_3" title="Permanent link">¶</a></h4>
<blockquote>
<p>CNN的历史副本是不可能通过一个作业全部洞悉的，故最终选择抛出两个具有代表性的模型</p>
<p>在后续的模型对比中，你还会再看见他们~</p>
</blockquote>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked id="__tabbed_2_1" name="__tabbed_2" type="radio"><input id="__tabbed_2_2" name="__tabbed_2" type="radio"><div class="tabbed-labels"><label for="__tabbed_2_1">ResNet</label><label for="__tabbed_2_2">VIT</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>ResNet 是一种基于卷积神经网络（CNN）的深度学习模型，其核心创新是引入了 <strong>残差连接（Residual Connection）</strong> ，使得网络可以构建非常深的网络（如 ResNet-152），并通过残差连接有效地训练这些深层网络，同时避免梯度消失问题。ResNet 在图像分类、目标检测等任务中表现优异，是计算机视觉领域的经典模型之一。</p>
<p>ResNet 的基本概念包括 <strong>残差块（Residual Block）</strong> 和 <strong>层次化特征提取</strong> 。每个残差块包含两个卷积层和一个跳跃连接（Shortcut Connection），跳跃连接将输入直接加到卷积层的输出上，形成残差学习。通过多个残差块的堆叠，ResNet 能够逐步从图像中提取从低级到高级的特征。</p>
<p>ResNet 的工作流程可以分为以下几个步骤：首先，通过 <strong>初始卷积层</strong> 对输入图像进行卷积操作，提取初步特征；接着，通过 <strong>残差块堆叠</strong> 逐步提取更复杂的特征；然后，使用 <strong>全局平均池化</strong> 对特征图进行下采样，降低维度；最后，将池化后的特征输入 <strong>全连接层</strong> ，完成分类任务。这种层次化的设计使得 ResNet 在图像分类、目标检测等任务中表现出色。</p>
</div>
<div class="tabbed-block">
<p>Transformer 引入图像处理领域，突破了传统卷积神经网络（CNN）的局部感受野限制。ViT 通过自注意力机制（Self-Attention）捕捉图像的全局信息，能够更好地理解图像中的长距离依赖关系。与传统的 CNN 不同，ViT 完全基于 Transformer，不使用卷积操作，这使得它在处理高分辨率图像时表现出色。</p>
<p>ViT 的基本概念包括 <strong>图像分块（Patch Embedding）</strong> 、 <strong>位置编码（Positional Encoding）和 Transformer 编码器</strong> 。首先，输入图像被分割成固定大小的块（如 16x16），每个块被展平为向量，并通过线性投影映射到嵌入空间。为了保留图像的空间信息，ViT 为每个图像块添加位置编码。随后，使用多层 Transformer 编码器对图像块进行特征提取，每层编码器包含自注意力机制和前馈神经网络。</p>
<p>ViT 的工作流程可以分为以下几个步骤：首先，将输入图像 <strong>分割成多个小块</strong> ，并将这些块映射到嵌入空间；接着，为每个图像块 <strong>添加位置编码</strong> ，以保留空间信息；然后，通过 <strong>多层 Transformer 编码器</strong> 提取特征；最后，使用 <strong>分类标记（CLS Token）</strong> 的输出进行最终分类。这种基于 Transformer 的设计使得 ViT 在处理复杂图像和全局信息时表现出色，成为计算机视觉领域的重要创新。</p>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">模型对比</p>
<p>两种模型，前者是现代CNN模型的<u>守门员</u>，另一者则为计算机视觉领域的<u>革新者</u>  </p>
<p>在计算机视觉领域各有优势</p>
<p>ResNet 在<u>传统任务</u>中表现优异</p>
<p>而 ViT 在处理<u>复杂图像和全局信息</u>时表现出色</p>
</div>
<hr>
<h3 id="cnn_2">最简单的CNN分类模型：逐行解析<a class="headerlink" href="#cnn_2" title="Permanent link">¶</a></h3>
<p>旨在厘清ML模型基本架构。</p>
<div class="admonition tip">
<p class="admonition-title">人生苦短，我选python</p>
<ul>
<li>本节代码多为demo，可能跑不起来  </li>
<li>带逐行的注释的完整代码见<a href="#_10">附录</a></li>
</ul>
</div>
<p>按照惯例，先上图~</p>
<pre class="mermaid"><code>flowchart TD
    A[开始] --&gt; B[依赖库导入与基本配置]
    subgraph B [依赖库导入与基本配置]
        direction LR
        B1[导入必要的库] --&gt; B2[设置随机种子] --&gt; B3[配置设备（CPU/GPU）]
    end

    B --&gt; C[数据集导入与处理]
    subgraph C [数据集导入与处理]
        direction LR
        C1[定义数据预处理] --&gt; C2[加载数据集] --&gt; C3[划分训练集和验证集] --&gt; C4[创建 DataLoader]
    end

    C --&gt; D[模型创建与实例化]
    subgraph D [模型创建与实例化]
        direction LR
        D1[定义 CNN 模型类] --&gt; D2[实例化模型] --&gt; D3[将模型移动到设备] --&gt; D4[定义损失函数和优化器]
    end

    D --&gt; E[训练与评估]
    subgraph E [训练与评估]
        direction LR
        E1[定义训练函数] --&gt; E2[定义验证函数] --&gt; E3[训练模型] --&gt; E4[测试模型] --&gt; E5[输出测试准确率]
    end

    E --&gt; F[结束]

    %% 样式优化 - 主模块
    style A fill:#8ECFC9,color:white,stroke:#8ECFC1,stroke-width:1px,stroke-dasharray:3
    style B fill:#82B0D2,color:white,stroke:#82B0D1,stroke-width:1px
    style C fill:#FFBE7A,color:white,stroke:#FFBE71,stroke-width:1px
    style D fill:#BEB8DC,color:white,stroke:#BEB8D1,stroke-width:1px
    style E fill:#E7DAD2,color:white,stroke:#E7DAD1,stroke-width:1px
    style F fill:#8ECFC9,color:white,stroke:#8ECFC1,stroke-width:1px,stroke-dasharray:3

    %% 样式优化 - 子模块
    style B1 fill:#BBDEFB,color:#000,stroke:#64B5F6,stroke-width:1px
    style B2 fill:#BBDEFB,color:#000,stroke:#64B5F6,stroke-width:1px
    style B3 fill:#BBDEFB,color:#000,stroke:#64B5F6,stroke-width:1px

    style C1 fill:#FFE0B2,color:#000,stroke:#FFB74D,stroke-width:1px
    style C2 fill:#FFE0B2,color:#000,stroke:#FFB74D,stroke-width:1px
    style C3 fill:#FFE0B2,color:#000,stroke:#FFB74D,stroke-width:1px
    style C4 fill:#FFE0B2,color:#000,stroke:#FFB74D,stroke-width:1px

    style D1 fill:#E1BEE7,color:#000,stroke:#BA68C8,stroke-width:1px
    style D2 fill:#E1BEE7,color:#000,stroke:#BA68C8,stroke-width:1px
    style D3 fill:#E1BEE7,color:#000,stroke:#BA68C8,stroke-width:1px
    style D4 fill:#E1BEE7,color:#000,stroke:#BA68C8,stroke-width:1px

    style E1 fill:#F8BBD0,color:#000,stroke:#F06292,stroke-width:1px
    style E2 fill:#F8BBD0,color:#000,stroke:#F06292,stroke-width:1px
    style E3 fill:#F8BBD0,color:#000,stroke:#F06292,stroke-width:1px
    style E4 fill:#F8BBD0,color:#000,stroke:#F06292,stroke-width:1px
    style E5 fill:#F8BBD0,color:#000,stroke:#F06292,stroke-width:1px


    linkStyle 0 stroke:#666,color;
    linkStyle 1 stroke:#666,color;
    linkStyle 2 stroke:#666,color;
    linkStyle 3 stroke:#666,color;   
    linkStyle 4 stroke:#666,color;
    linkStyle 5 stroke:#666,color;
    linkStyle 6 stroke:#666,color;
    linkStyle 7 stroke:#666,color;  
    linkStyle 8 stroke:#666,color;
    linkStyle 9 stroke:#666,color;
    linkStyle 10 stroke:#666,color;
    linkStyle 11 stroke:#666,color;
    linkStyle 12 stroke:#666,color;
    linkStyle 13 stroke:#666,color;
    linkStyle 14 stroke:#666,color;
    linkStyle 15 stroke:#666,color;   
    linkStyle 16 stroke:#666,color; 
</code></pre>
<p></p><center style="font-size:14px;color:#C0C0C0;">图2 pytorch典型ML代码流程图</center>
<blockquote>
<p>地图有了，就可以愉快的解构代码一一映射啦<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>🫡</p>
</blockquote>
<hr>
<div class="tabbed-set tabbed-alternate" data-tabs="3:4"><input checked id="__tabbed_3_1" name="__tabbed_3" type="radio"><input id="__tabbed_3_2" name="__tabbed_3" type="radio"><input id="__tabbed_3_3" name="__tabbed_3" type="radio"><input id="__tabbed_3_4" name="__tabbed_3" type="radio"><div class="tabbed-labels"><label for="__tabbed_3_1">依赖库导入与基本配置</label><label for="__tabbed_3_2">数据集导入与处理</label><label for="__tabbed_3_3">模型创建与实例化</label><label for="__tabbed_3_4">模型训练与评估</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<blockquote>
<p>巧妇难为无米之炊，一个项目往往需要数个功能各异的库协同合作</p>
</blockquote>
<p><strong>导入必要的库</strong></p>
<ul>
<li><code>torch</code>：PyTorch 的核心库，用于张量操作和深度学习模型</li>
<li><code>torch.nn</code>：PyTorch 的神经网络模块，包含层和损失函数</li>
<li><code>torch.nn.functional</code>：包含激活函数等操作</li>
<li><code>torch.optim</code>：优化算法模块，如 SGD 和 Adam</li>
<li><code>torchvision</code>：用于处理图像数据集和图像变换</li>
<li><code>DataLoader</code> 和 <code>random_split</code>：用于加载和划分数据集</li>
<li><code>einops</code>：用于张量操作的高级库</li>
<li><code>matplotlib.pyplot</code>：用于绘制图表</li>
<li><code>time</code>：用于计算时间</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="kn">from</span><span class="w"> </span><span class="nn">einops</span><span class="w"> </span><span class="kn">import</span> <span class="n">rearrange</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</code></pre></div>
<p><strong>设置随机种子</strong></p>
<p>设置随机种子为 99，确保<sub>~代码复活</sub>~每次运行代码时结果可重复。</p>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># 固定随机种子</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">99</span><span class="p">)</span>
</code></pre></div>
<p><strong>设备配置</strong></p>
<p>这一步是必要的，A卡就老老实实用CPU吧</p>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># 获取设备（CPU 或 GPU）</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"Using </span><span class="si">{}</span><span class="s2"> device"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p>在介绍数据处理前，先简要说明一下大名鼎鼎的<code>Fashion MNIST</code>数据集。</p>
<p>Fashion MNIST 数据集是 10 个时尚类别的灰度图像集合，每个图像大小为 <mark>28x28</mark> 像素。它用作经典 MNIST 数据集的替代品。由于服装项目相似，因此它的分类问题比常规 MNIST 数字数据集更具挑战性。</p>
<p></p><center>
<p><a class="glightbox" href="https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png" alt="Fashion MNIST Sample" style="zoom: 50%;"></a></p>
<p></p></center>
<center style="font-size:14px;color:#C0C0C0;">图3  数据集概览|图源网络</center>
<p>数据集中每幅图像对应一个0~9的标签，代表十个类别：</p>
<p></p><center>
<table>
<thead>
<tr>
<th>Label</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>T-shirt/top</td>
</tr>
<tr>
<td>1</td>
<td>Trouser</td>
</tr>
<tr>
<td>2</td>
<td>Pullover</td>
</tr>
<tr>
<td>3</td>
<td>Dress</td>
</tr>
<tr>
<td>4</td>
<td>Coat</td>
</tr>
<tr>
<td>5</td>
<td>Sandal</td>
</tr>
<tr>
<td>6</td>
<td>Shirt</td>
</tr>
<tr>
<td>7</td>
<td>Sneaker</td>
</tr>
<tr>
<td>8</td>
<td>Bag</td>
</tr>
<tr>
<td>9</td>
<td>Ankle boot</td>
</tr>
</tbody>
</table>
<p></p></center>
<center style="font-size:14px;color:#C0C0C0;">表1  Fashion MNIST数据集类别</center>
<p><strong>数据预处理</strong></p>
<ul>
<li><code>ToTensor()</code>：将图像转换为 PyTorch 张量</li>
<li><code>Normalize((0.5,), (0.5,))</code>：将像素值从 [0, 1] 归一化到 [-1, 1]</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))</span>  <span class="c1"># 归一化到[-1, 1]</span>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="p">])</span>
</code></pre></div>
<p><strong>下载数据集</strong></p>
<ul>
<li><code>root='./data'</code>：数据集存储路径</li>
<li><code>train=True</code>：加载训练集|<code>train=False</code>：加载测试集</li>
<li><code>download=True</code>：如果数据集不存在，则自动下载</li>
<li><code>transform=transform</code>：应用定义的数据预处理</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>    <span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> 
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span>
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="p">)</span>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    <span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> 
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span>
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="p">)</span>
</code></pre></div>
<p><strong>数据集划分</strong></p>
<p>将训练集划分为训练集和验证集：</p>
<ul>
<li><code>train_size</code>：训练集大小（80%）</li>
<li><code>val_size</code>：验证集大小（20%）</li>
<li><code>random_split</code>：随机划分数据集</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">val_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">])</span>
</code></pre></div>
<p><strong>创建DataLoader</strong></p>
<ul>
<li><code>batch_size=64</code>：每次加载 64 张图片</li>
<li><code>shuffle=True</code>：训练集打乱顺序，验证集和测试集不打乱</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1"># 创建DataLoader</span>
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">题外话——数据处理用到的库</p>
<p><code>torchvision</code>是 PyTorch 生态系统中的一个库，它提供了一套用于计算机视觉的实用程序。它提供：</p>
<ul>
<li>预训练模型（如 ResNet、VGG 和 AlexNet）</li>
<li>流行的数据集和用于预处理这些数据集的转换</li>
<li>用于创建自定义数据集和数据加载器的实用程序</li>
</ul>
<p>我们主要用于<code>torchvision</code>访问 Fashion MNIST 数据集并对图像应用转换</p>
<hr>
<p><code>torch.utils</code>是 PyTorch 中的一个实用模块，它提供了多个子模块来协助完成各种任务。</p>
<p>其最常用的子模块之一是<code>data</code>，它有助于处理数据集并提供工具来高效地加载和预处理数据。</p>
<hr>
<p><code>DataLoader</code> <code>torch.utils.data</code>是一个包装数据集并提供小批量数据的类。它提供：</p>
<ul>
<li>数据分批：为了更好地优化和更快地进行训练，我们经常对小批量数据进行训练，而不是对整个数据集进行训练</li>
<li>混洗：在每个时期开始时随机地重新排序训练数据，以减少模型方差</li>
<li>并行加载：使用多线程在后台准备批次，确保 GPU/CPU 保持繁忙</li>
</ul>
<blockquote>
<p>说人话，洗牌的🤪</p>
</blockquote>
</div>
</div>
<div class="tabbed-block">
<p>以最典型的CNN为例，不涉及Dropout。工作流程在<a href="#_2">上一节</a>已有所说明。</p>
<p><strong>定义CNN模型类</strong></p>
<ul>
<li><code>conv1</code>：第一层卷积，输入通道 1，输出通道 32，卷积核大小 3x3</li>
<li><code>conv2</code>：第二层卷积，输入通道 32，输出通道 64，卷积核大小 3x3</li>
<li><code>fc1</code>：全连接层，输入大小为 64*7*7，输出大小为 128</li>
<li><code>fc2</code>：全连接层，输入大小为 128，输出大小为 10（对应 10 个类别）</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div>
<p><strong>前向传播</strong></p>
<p>有以下过程：</p>
<ul>
<li>通过卷积层和 ReLU 激活函数提取特征</li>
<li>通过最大池化层下采样</li>
<li>将特征展平为一维向量</li>
<li>通过全连接层和 ReLU 激活函数进行分类</li>
<li>返回最终的输出</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<p><strong>模型实例化</strong></p>
<p>即创建模型的一个实例并将其传输到适当的设备（CPU 或 GPU）</p>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<p><strong>优化器与损失函数</strong></p>
<ul>
<li>优化器：Adam 优化器是常用的，可在训练期间调整学习率</li>
<li>损失函数：由于这是一个分类任务，我们使用交叉熵损失</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">题外话——优化器与损失函数的选择</p>
<p><strong>优化器</strong></p>
<p>优化器是根据损失函数的梯度来调整模型权重的算法。目标是最小化损失。有几种可用的优化器：</p>
<ol>
<li><strong>SGD（随机梯度下降）</strong>：这是梯度下降算法的基本形式。它使用损失函数对每个权重的梯度来更新模型的权重。
- 使用：<code>torch.optim.SGD(model.parameters(), lr=learning_rate)</code></li>
<li><strong>动量</strong>：SGD 的一种变体，它考虑到了前面的步骤，有助于加速收敛并避免局部最小值。
- 使用：<code>torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)</code></li>
<li><strong>Adam</strong>：结合了 SGD 的另外两个扩展，即 AdaGrad 和 RMSProp 的优点。它根据历史梯度信息调整每个权重的学习率。
- 使用：<code>torch.optim.Adam(model.parameters(), lr=learning_rate)</code></li>
<li><strong>RMSProp</strong>：保持梯度平方的移动平均值，并将梯度除以该平均值的根。
- 使用：<code>torch.optim.RMSprop(model.parameters(), lr=learning_rate)</code></li>
</ol>
<hr>
<p><strong>损失函数</strong></p>
<ol>
<li><strong>交叉熵损失</strong>：用于多类分类。它量化了预测概率分布和实际分布之间的差异。
- 使用：<code>nn.CrossEntropyLoss()</code></li>
<li><strong>二元交叉熵损失</strong>：专门用于二元分类任务。
- 使用：<code>nn.BCELoss()</code></li>
<li><strong>Hinge Loss（或 Margin Loss）</strong>：用于“最大边缘”分类，主要用于 SVM。
- 使用：<code>nn.HingeEmbeddingLoss()</code></li>
</ol>
<blockquote>
<p>根据既定任务因地制宜</p>
</blockquote>
</div>
</div>
<div class="tabbed-block">
<p><strong>训练</strong></p>
<p>训练神经网络涉及迭代更新其权重以最小化损失函数。此过程通常使用梯度下降优化算法来实现。</p>
<p>一般包含：</p>
<ul>
<li><strong>Epochs</strong>：一个epoch代表所有训练样例的一次完整的前向和后向传递。周期数 (num_epochs) 是学习算法遍历整个训练数据集的次数。通常是自定义超参数</li>
<li><strong>模型训练模式</strong>：神经网络可以以不同的模式运行——训练和评估</li>
<li><strong>批处理</strong>：我们通常在一组称为批次的训练示例之后更新权重，而不是在每个训练示例（随机梯度下降）或整个数据集（批量梯度下降）之后更新权重</li>
<li><strong>梯度归零</strong>：在 PyTorch 中，默认情况下梯度会累积。在计算当前批次中的新梯度之前，我们需要将先前的梯度设置为零</li>
<li><strong>前向传递</strong>：输入数据（图像）通过网络逐层传递，直到得到输出。这个过程称为前向传播</li>
<li><strong>计算损失</strong>：一旦我们有了网络的预测（输出），我们就使用损失函数将它们与真实标签进行比较。这可以衡量网络的预测与实际标签的匹配程度</li>
<li><strong>反向传播</strong>：为了更新权重，我们需要知道损失函数相对于每个权重的梯度。向后传递计算这些梯度</li>
<li><strong>更新权重</strong>：优化器根据向后传递中计算的梯度更新权重</li>
</ul>
<p>对于数据集中的每个批次重复此循环（前向传递、损失计算、后向传递、权重更新）。</p>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="c1"># 迭代次数</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="c1"># Start the training loop</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="c1"># 将模型设置为训练模式</span>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>    <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>    <span class="c1"># 迭代每批训练数据</span>
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">):</span>
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>        <span class="c1"># 将图像和标签移动到计算设备（CPU 或 GPU）</span>
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>        <span class="c1"># 清除上一次迭代的梯度</span>
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>        <span class="c1"># 前向传递：将图像传递给模型以获得预测输出</span>
<a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>        <span class="c1"># 计算预测输出和真实标签之间的损失</span>
<a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a>        <span class="c1"># 向后传递：计算损失 w.r.t 的梯度。模型参数</span>
<a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> 
<a id="__codelineno-11-21" name="__codelineno-11-21" href="#__codelineno-11-21"></a>        <span class="c1"># 更新模型参数</span>
<a id="__codelineno-11-22" name="__codelineno-11-22" href="#__codelineno-11-22"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-11-23" name="__codelineno-11-23" href="#__codelineno-11-23"></a>        <span class="c1"># Print the loss every 100 batches</span>
<a id="__codelineno-11-24" name="__codelineno-11-24" href="#__codelineno-11-24"></a>        <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-11-25" name="__codelineno-11-25" href="#__codelineno-11-25"></a>            <span class="n">loss</span><span class="p">,</span> <span class="n">current</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">batch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<a id="__codelineno-11-26" name="__codelineno-11-26" href="#__codelineno-11-26"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">&gt;7f</span><span class="si">}</span><span class="s2">  [</span><span class="si">{</span><span class="n">current</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">]"</span><span class="p">)</span>
</code></pre></div>
<p><strong>评估（测试）</strong></p>
<p>一旦我们的模型训练完成，评估其在未知数据上的表现就至关重要。</p>
<ul>
<li>使用测试集评估准确度与泛用性</li>
<li>打印报告与绘制结果（如果你愿意的话）</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="c1"># 将模型设置为评估模式</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="c1"># 用于存储所有预测和真实标签的列表</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="n">all_preds</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="c1"># 使用 torch.no_grad() 计算梯度</span>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>        <span class="c1"># 将图像传递给模型以获取预测</span>
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>        <span class="c1"># 获取具有最大概率的类作为预测类</span>
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>        <span class="c1"># 使用真实标签和预测计算混淆矩阵</span>
<a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>        <span class="n">all_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>        <span class="c1"># 使用此批次中的真实标签扩展all_labels列表</span>
<a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>        <span class="n">all_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a><span class="c1"># 打印报告</span>
<a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a><span class="c1"># 绘制结果</span>
</code></pre></div>
</div>
</div>
</div>
<h2 id="putting-cnn-to-work">Putting CNN to Work<a class="headerlink" href="#putting-cnn-to-work" title="Permanent link">¶</a></h2>
<blockquote>
<p>多说无益，在电脑风扇呼啸之前，你永远无法真切感受到ML的魅力！</p>
</blockquote>
<div class="admonition info">
<p class="admonition-title">MY ENVIRONMENT</p>
<ol>
<li><strong>Anaconda</strong>：<a href="https://anaconda.org/">环境管理器</a>，base八宝粥破坏者</li>
<li><strong>Python</strong>：最好是Python 3.x</li>
<li><strong>PyTorch 和 torchvision</strong>：<a href="https://pytorch.org/">PyTorch</a> 是一个开源机器学习库，torchvision 提供计算机视觉的数据集和模型</li>
<li><strong>Jupyter Notebook</strong>：<a href="https://jupyter.org/">交互式环境</a>，基于Vscode编译器</li>
<li><strong>NumPy</strong>：Python 中的数值运算库</li>
<li><strong>scikit-learn</strong>：Python 中的机器学习库。我们将使用它来获取性能指标</li>
<li><strong>Seaborn 和 Matplotlib</strong>：Python 中的可视化库</li>
<li><strong>CUDA（可选）</strong>：如果您有兼容的 NVIDIA GPU，则可以安装 CUDA 以实现 PyTorch 的 GPU 加速</li>
</ol>
</div>
<div class="admonition tip">
<p class="admonition-title">可能需要的：</p>
<ul>
<li><a href="https://blog.csdn.net/qq_45057249/article/details/130438318">Anaconda + Pytorch 超详细安装教程</a></li>
<li><a href="https://blog.csdn.net/chenxy_bwave/article/details/119996001">conda常用命令：从入门到入土</a></li>
<li>对于<code>pip/pipx</code>下载，若遇到下载速度过慢，不妨给定镜像源（通常是清华/阿里），即</li>
</ul>
<div class="highlight"><span class="filename">powershell</span><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">-i</span> <span class="n">https</span><span class="p">://</span><span class="n">pypi</span><span class="p">.</span><span class="n">tuna</span><span class="p">.</span><span class="n">tsinghua</span><span class="p">.</span><span class="n">edu</span><span class="p">.</span><span class="n">cn</span><span class="p">/</span><span class="n">simple</span>
</code></pre></div>
<ul>
<li>非大项目，建议转战<code>Vscode</code>，ALL IN ONE它不香嘛😜</li>
</ul>
</div>
<hr>
<h3 id="running">RUNNING！<a class="headerlink" href="#running" title="Permanent link">¶</a></h3>
<p>本节将从两个方面 <del>拷打</del> 测试CNN</p>
<ul>
<li>控制模型，改变超参（学习率lr、优化器、激活函数）</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="c1"># 定义不同的参数组合</span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">]</span>
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="n">activation_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">]</span>
</code></pre></div>
<ul>
<li>控制超参，改变模型</li>
</ul>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="c1"># 定义模型列表</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>    <span class="s1">'CNN'</span><span class="p">:</span> <span class="n">CNN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>    <span class="s1">'ResNet'</span><span class="p">:</span> <span class="n">ResNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>    <span class="s1">'ViT'</span><span class="p">:</span> <span class="n">ViT</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a><span class="p">}</span>
</code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked id="__tabbed_4_1" name="__tabbed_4" type="radio"><input id="__tabbed_4_2" name="__tabbed_4" type="radio"><div class="tabbed-labels"><label for="__tabbed_4_1">The Impact of Hyperparameters on Model Performance</label><label for="__tabbed_4_2">Who Wears the Crown of FashionMNIST Classification</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><strong>训练与测试结果</strong></p>
<p></p><center>
<p><a class="glightbox" href="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/CNN_25_1.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/CNN_25_1.png" style="zoom:60%;"></a></p>
<p></p></center>
<p></p><center style="font-size:14px;color:#C0C0C0;">图4 不同超参下的模型性能结果对比</center>
<p></p><center>
<table>
<thead>
<tr>
<th style="text-align: center;">Learning Rate</th>
<th style="text-align: center;">Optimizer</th>
<th style="text-align: center;">Activation Function</th>
<th style="text-align: center;">Training Time (s)</th>
<th style="text-align: center;">Inference Time (ms)</th>
<th style="text-align: center;">Test Loss</th>
<th style="text-align: center;">Test Accuracy</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Model Size (Bytes)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">relu</td>
<td style="text-align: center;">241.59</td>
<td style="text-align: center;">0.103</td>
<td style="text-align: center;">0.3053</td>
<td style="text-align: center;">0.9134</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">leaky_relu</td>
<td style="text-align: center;">240.98</td>
<td style="text-align: center;">0.106</td>
<td style="text-align: center;">0.2808</td>
<td style="text-align: center;">0.9161</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">SGD</td>
<td style="text-align: center;">relu</td>
<td style="text-align: center;">244.02</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">0.5782</td>
<td style="text-align: center;">0.7879</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">SGD</td>
<td style="text-align: center;">leaky_relu</td>
<td style="text-align: center;">245.92</td>
<td style="text-align: center;">0.107</td>
<td style="text-align: center;">0.5764</td>
<td style="text-align: center;">0.7905</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">relu</td>
<td style="text-align: center;">253.14</td>
<td style="text-align: center;">0.114</td>
<td style="text-align: center;">0.3572</td>
<td style="text-align: center;">0.8729</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">leaky_relu</td>
<td style="text-align: center;">267.85</td>
<td style="text-align: center;">0.115</td>
<td style="text-align: center;">0.3834</td>
<td style="text-align: center;">0.8640</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">SGD</td>
<td style="text-align: center;">relu</td>
<td style="text-align: center;">277.47</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.3529</td>
<td style="text-align: center;">0.8718</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">SGD</td>
<td style="text-align: center;">leaky_relu</td>
<td style="text-align: center;">273.44</td>
<td style="text-align: center;">0.119</td>
<td style="text-align: center;">0.3508</td>
<td style="text-align: center;">0.8704</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">relu</td>
<td style="text-align: center;">278.61</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">2.3124</td>
<td style="text-align: center;">0.1000</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">Adam</td>
<td style="text-align: center;">leaky_relu</td>
<td style="text-align: center;">258.18</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">2.3089</td>
<td style="text-align: center;">0.1000</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">SGD</td>
<td style="text-align: center;">relu</td>
<td style="text-align: center;">249.44</td>
<td style="text-align: center;">0.117</td>
<td style="text-align: center;">0.2546</td>
<td style="text-align: center;">0.9131</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
<tr>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">SGD</td>
<td style="text-align: center;">leaky_relu</td>
<td style="text-align: center;">252.32</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.2749</td>
<td style="text-align: center;">0.9087</td>
<td style="text-align: center;">421642</td>
<td style="text-align: center;">1686568</td>
</tr>
</tbody>
</table>
<p></p></center>
<p></p><center style="font-size:14px;color:#C0C0C0;">表2 不同超参下的模型测试结果与复杂度计算</center>
<p><strong>不同学习率对Loss的影响</strong></p>
<p><strong>低学习率（如0.001）</strong>：</p>
<ul>
<li>低学习率使模型每次更新的步幅较小，导致训练过程较稳定，但需要更多迭代次数才能收敛</li>
<li>优势：能避免梯度爆炸或不稳定收敛</li>
<li>缺点：训练时间长</li>
</ul>
<p><strong>高学习率（如0.1）</strong>：</p>
<ul>
<li>高学习率使每次权重更新幅度较大，可能导致Loss在最优值附近振荡甚至发散</li>
<li>实验中的验证集Loss较大波动，说明模型未能有效学习目标函数</li>
</ul>
<p><strong>最佳学习率（0.001）</strong>：</p>
<ul>
<li>稳定下降且最终Loss最低，证明其兼顾了收敛速度和准确性。</li>
</ul>
<hr>
<p><strong>不同优化器对Loss的影响</strong></p>
<p><strong>Adam优化器</strong>：</p>
<ul>
<li>Adam结合了动量与自适应学习率的优点，能自动调整每个参数的学习率，特别在非凸优化问题中表现良好</li>
<li>实验中，Adam收敛速度快，Loss曲线陡峭下降，验证集Loss也较低</li>
<li>在高学习率时崩坏，不能使用</li>
</ul>
<p><strong>SGD优化器</strong>：</p>
<ul>
<li>SGD采用固定学习率，优化过程依赖于梯度的全局方向。</li>
<li>在实验中，SGD表现出收敛慢的特性，训练时间较长，但在高lr时表现出更稳定更优秀的特性。</li>
</ul>
<hr>
<p><strong>不同激活函数对Loss的影响</strong></p>
<p><strong>ReLU激活函数</strong>：</p>
<ul>
<li>ReLU对正值保持线性，而对负值输出0，计算高效且收敛速度快</li>
<li>实验中，ReLU的训练和验证Loss曲线平滑下降，且验证Loss较低，表明模型学到了有效的特征</li>
</ul>
<p><strong>Leaky ReLU激活函数</strong>：</p>
<ul>
<li>Leaky ReLU在负值区域提供了微小的负斜率，避免了“神经元死亡”的问题</li>
<li>实验中，Leaky ReLU的验证Loss在初期低于ReLU，但中后期波动较大，可能因较复杂的负值梯度学习带来不稳定</li>
</ul>
<hr>
<p><strong>测试Loss和准确率（Test Accuracy）</strong>：</p>
<ul>
<li><code>lr=0.001, Adam, ReLU</code>的测试Accuracy最高（0.9134），表明其泛化能力最佳。</li>
<li>高学习率（如0.1）或使用Adam时，测试Loss和准确率下降，说明模型可能过拟合或欠拟合。</li>
</ul>
<p><strong>训练时间与推理时间</strong>：</p>
<ul>
<li>Adam优化器需要更多计算量以动态调整学习率，因此训练时间略长。</li>
<li>推理时间与模型大小无关，因此不同超参数配置下几乎相同。</li>
</ul>
<hr>
<p><strong>一些结论</strong></p>
<ol>
<li><strong>学习率的平衡</strong>：0.001提供了最佳的稳定性与收敛效果</li>
<li><strong>优化器的选择</strong>：Adam表现更快，但SGD在某些场景可实现竞争力</li>
<li><strong>激活函数的取舍</strong>：ReLU更稳健，而Leaky ReLU有潜在优势但波动较大</li>
<li><strong>泛化能力</strong>：测试集表现上，<code>lr=0.001, Adam, ReLU</code>显然是最优选择</li>
</ol>
</div>
<div class="tabbed-block">
<p><strong>训练与测试结果</strong></p>
<p></p><center>
<p><a class="glightbox" href="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/CNN_28_1.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/CNN_28_1.png" style="zoom:100%;"></a></p>
<p></p></center>
<p></p><center style="font-size:14px;color:#C0C0C0;">图5 不同模型的模型性能结果对比</center>
<table>
<thead>
<tr>
<th>Model</th>
<th>Parameters</th>
<th>Model Size (Bytes)</th>
<th>Training Time (s)</th>
<th>Avg. Inference Time per Sample (ms)</th>
<th>Test Loss</th>
<th>Test Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNN</td>
<td>421642</td>
<td>1686568</td>
<td>307.94</td>
<td>0.139</td>
<td>0.3065</td>
<td>0.9116</td>
</tr>
<tr>
<td><strong>ResNet</strong></td>
<td><strong>11172810</strong></td>
<td><strong>44691240</strong></td>
<td><strong>6906.87</strong></td>
<td><strong>0.4027</strong></td>
<td><strong>0.3030</strong></td>
<td><strong>0.9189</strong></td>
</tr>
<tr>
<td>ViT</td>
<td>139018</td>
<td>556072</td>
<td>399.43</td>
<td>0.138</td>
<td>2.3033</td>
<td>0.1000</td>
</tr>
</tbody>
</table>
<p></p><center style="font-size:14px;color:#C0C0C0;">表3 不同模型下的性能结果对比</center>
<p><strong>训练和验证损失分析</strong></p>
<ul>
<li><strong>CNN</strong> 和 <strong>ResNet</strong> 的训练和验证损失整体较低，且变化趋势较为稳定。随着 epoch 增加，损失逐渐减小，但 <strong>CNN</strong> 训练后期可能出现轻微的过拟合现象（如验证损失略有增加）。</li>
<li><strong>ViT</strong> 的训练损失与验证损失非常高，说明模型可能欠拟合。</li>
</ul>
<p><strong>参数量与模型大小</strong></p>
<ul>
<li><strong>CNN</strong> 参数量适中（421,642），表明 CNN 是一个轻量级模型，适合资源受限的设备</li>
<li><strong>ResNet</strong> 的参数量显著增加（11,172,810），模型大小最大（~44.69 MB），表明它更复杂，更适合处理更复杂的数据或任务</li>
<li><strong>ViT</strong> 的参数量最少（139,018），模型大小也最小（~0.56 MB），理论上应该具备更快的推理速度，但其性能可能受到数据集规模和模型架构的影响</li>
</ul>
<p><strong>训练时间与推理时间</strong></p>
<ul>
<li><strong>CNN</strong> 的训练时间最短（307.94 秒），推理时间也最低，表明它效率最高，非常适合快速迭代</li>
<li><strong>ResNet</strong> 的训练时间超级长（6,906.87 秒），推理时间也相对较高，但它在分类任务中的表现优异</li>
<li><strong>ViT</strong> 的训练时间则略长于 <strong>CNN</strong>（399.43 秒）</li>
</ul>
<p><strong>测试损失与准确率</strong></p>
<ul>
<li><strong>CNN</strong> 和 <strong>ResNet</strong> 在测试集上的损失较低（分别为 0.3065 和 0.3030），且测试准确率较高（分别为 91.16% 和 91.89%）</li>
<li><strong>ResNet</strong> 的表现略优于 <strong>CNN</strong></li>
<li><strong>ViT</strong> 的测试损失高达 2.3033，测试准确率仅为 10%，这纯纯在猜啊🤣。这表明 <strong>ViT</strong> 未能很好地学习到 FashionMNIST 的特征</li>
</ul>
<p><strong>结论</strong></p>
<ul>
<li><strong>CNN</strong> 是一个轻量级、高效的模型，在准确率和推理时间之间取得了良好的平衡。</li>
<li><strong>ResNet</strong> 是一个强大的模型，在性能上稍胜一筹，但需要更多的训练时间和资源。</li>
<li><strong>ViT</strong> 的表现极差，可能是因为 ViT 对训练数据的规模和多样性更为敏感，而 FashionMNIST 数据集较小，导致模型未能充分发挥其优势。</li>
</ul>
<p><strong><mark>对于 FashionMNIST 数据集</mark></strong></p>
<ul>
<li>
<p><strong>ResNet</strong> 是综合表现最好的模型，其次是 <strong>CNN</strong></p>
</li>
<li>
<p><strong>ViT</strong> 在该任务中不适用，但在更复杂的任务中可能更有潜力。</p>
</li>
</ul>
<div class="admonition abstract">
<p class="admonition-title">补充</p>
<p>若服务器是A卡，即不能GPU加速，则很明显 <strong>经典CNN</strong> 才是 <strong>Champion</strong> 。相差不多的准确率，等 <strong>ResNet</strong> 跑完人都麻了。</p>
<p>但实际上基本都是用的GPU，基本上是10倍效率往上，所以相对来说 <strong>ResNet</strong> 的时间是可以接受的，故其为最优解</p>
<p>当然， <strong>VIT</strong> 本就是拿来划水了，这点样本量都不够剔牙捏~</p>
</div>
</div>
</div>
</div>
<hr>
<h2 id="_4">最后<a class="headerlink" href="#_4" title="Permanent link">¶</a></h2>
<p>这是笔者第一次从查阅资料到实验结果分析，系统地走了一遍。</p>
<p>期末周匆匆忙忙赶出来的，也是漏洞百出。</p>
<p>但总算是结束啦~</p>
<h2 id="_5">附录<a class="headerlink" href="#_5" title="Permanent link">¶</a></h2>
<div class="highlight"><span class="filename">python</span><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="c1"># 导入必要的库</span>
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>  <span class="c1"># PyTorch 核心库，用于张量操作和深度学习模型</span>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>  <span class="c1"># PyTorch 的神经网络模块，包含层和损失函数</span>
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>  <span class="c1"># 包含激活函数等操作</span>
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>  <span class="c1"># 优化算法模块，如 SGD 和 Adam</span>
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>  <span class="c1"># 用于处理图像数据集和图像变换</span>
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>  <span class="c1"># 用于加载和划分数据集</span>
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a><span class="kn">from</span><span class="w"> </span><span class="nn">einops</span><span class="w"> </span><span class="kn">import</span> <span class="n">rearrange</span>  <span class="c1"># 用于张量操作的高级库</span>
<a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># 用于绘制图表</span>
<a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>  <span class="c1"># 用于计算时间</span>
<a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a>
<a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a><span class="c1"># 固定随机种子，确保每次运行代码时结果可重复</span>
<a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">99</span><span class="p">)</span>
<a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>
<a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a><span class="c1"># 获取设备（CPU 或 GPU），优先使用 GPU</span>
<a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
<a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a><span class="nb">print</span><span class="p">(</span><span class="s2">"Using </span><span class="si">{}</span><span class="s2"> device"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>  <span class="c1"># 打印当前使用的设备</span>
<a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a>
<a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a><span class="c1"># 数据预处理</span>
<a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
<a id="__codelineno-16-21" name="__codelineno-16-21" href="#__codelineno-16-21"></a>    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>  <span class="c1"># 将图像转换为 PyTorch 张量</span>
<a id="__codelineno-16-22" name="__codelineno-16-22" href="#__codelineno-16-22"></a>    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))</span>  <span class="c1"># 将像素值从 [0, 1] 归一化到 [-1, 1]</span>
<a id="__codelineno-16-23" name="__codelineno-16-23" href="#__codelineno-16-23"></a><span class="p">])</span>
<a id="__codelineno-16-24" name="__codelineno-16-24" href="#__codelineno-16-24"></a>
<a id="__codelineno-16-25" name="__codelineno-16-25" href="#__codelineno-16-25"></a><span class="c1"># 加载 Fashion MNIST 数据集</span>
<a id="__codelineno-16-26" name="__codelineno-16-26" href="#__codelineno-16-26"></a><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
<a id="__codelineno-16-27" name="__codelineno-16-27" href="#__codelineno-16-27"></a>    <span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span>  <span class="c1"># 数据集存储路径</span>
<a id="__codelineno-16-28" name="__codelineno-16-28" href="#__codelineno-16-28"></a>    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 加载训练集</span>
<a id="__codelineno-16-29" name="__codelineno-16-29" href="#__codelineno-16-29"></a>    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 如果数据集不存在，则自动下载</span>
<a id="__codelineno-16-30" name="__codelineno-16-30" href="#__codelineno-16-30"></a>    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span>  <span class="c1"># 应用定义的数据预处理</span>
<a id="__codelineno-16-31" name="__codelineno-16-31" href="#__codelineno-16-31"></a><span class="p">)</span>
<a id="__codelineno-16-32" name="__codelineno-16-32" href="#__codelineno-16-32"></a><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
<a id="__codelineno-16-33" name="__codelineno-16-33" href="#__codelineno-16-33"></a>    <span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span>  <span class="c1"># 数据集存储路径</span>
<a id="__codelineno-16-34" name="__codelineno-16-34" href="#__codelineno-16-34"></a>    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># 加载测试集</span>
<a id="__codelineno-16-35" name="__codelineno-16-35" href="#__codelineno-16-35"></a>    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 如果数据集不存在，则自动下载</span>
<a id="__codelineno-16-36" name="__codelineno-16-36" href="#__codelineno-16-36"></a>    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span>  <span class="c1"># 应用定义的数据预处理</span>
<a id="__codelineno-16-37" name="__codelineno-16-37" href="#__codelineno-16-37"></a><span class="p">)</span>
<a id="__codelineno-16-38" name="__codelineno-16-38" href="#__codelineno-16-38"></a>
<a id="__codelineno-16-39" name="__codelineno-16-39" href="#__codelineno-16-39"></a><span class="c1"># 划分训练集和验证集</span>
<a id="__codelineno-16-40" name="__codelineno-16-40" href="#__codelineno-16-40"></a><span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>  <span class="c1"># 训练集大小（80%）</span>
<a id="__codelineno-16-41" name="__codelineno-16-41" href="#__codelineno-16-41"></a><span class="n">val_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>  <span class="c1"># 验证集大小（20%）</span>
<a id="__codelineno-16-42" name="__codelineno-16-42" href="#__codelineno-16-42"></a><span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">])</span>  <span class="c1"># 随机划分数据集</span>
<a id="__codelineno-16-43" name="__codelineno-16-43" href="#__codelineno-16-43"></a>
<a id="__codelineno-16-44" name="__codelineno-16-44" href="#__codelineno-16-44"></a><span class="c1"># 创建 DataLoader</span>
<a id="__codelineno-16-45" name="__codelineno-16-45" href="#__codelineno-16-45"></a><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 训练集 DataLoader，打乱顺序</span>
<a id="__codelineno-16-46" name="__codelineno-16-46" href="#__codelineno-16-46"></a><span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># 验证集 DataLoader，不打乱顺序</span>
<a id="__codelineno-16-47" name="__codelineno-16-47" href="#__codelineno-16-47"></a><span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># 测试集 DataLoader，不打乱顺序</span>
<a id="__codelineno-16-48" name="__codelineno-16-48" href="#__codelineno-16-48"></a>
<a id="__codelineno-16-49" name="__codelineno-16-49" href="#__codelineno-16-49"></a><span class="c1"># 标准 CNN 模型</span>
<a id="__codelineno-16-50" name="__codelineno-16-50" href="#__codelineno-16-50"></a><span class="k">class</span><span class="w"> </span><span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-16-51" name="__codelineno-16-51" href="#__codelineno-16-51"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-16-52" name="__codelineno-16-52" href="#__codelineno-16-52"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-16-53" name="__codelineno-16-53" href="#__codelineno-16-53"></a>        <span class="c1"># 第一层卷积，输入通道 1，输出通道 32</span>
<a id="__codelineno-16-54" name="__codelineno-16-54" href="#__codelineno-16-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
<a id="__codelineno-16-55" name="__codelineno-16-55" href="#__codelineno-16-55"></a>        <span class="c1"># 第二层卷积，输入通道 32，输出通道 64</span>
<a id="__codelineno-16-56" name="__codelineno-16-56" href="#__codelineno-16-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<a id="__codelineno-16-57" name="__codelineno-16-57" href="#__codelineno-16-57"></a>        <span class="c1"># 全连接层，输入大小为 64*7*7，输出大小为 128   </span>
<a id="__codelineno-16-58" name="__codelineno-16-58" href="#__codelineno-16-58"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span> 
<a id="__codelineno-16-59" name="__codelineno-16-59" href="#__codelineno-16-59"></a>        <span class="c1"># 全连接层，输入大小为 128，输出大小为 10（对应 10 个类别）</span>
<a id="__codelineno-16-60" name="__codelineno-16-60" href="#__codelineno-16-60"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  
<a id="__codelineno-16-61" name="__codelineno-16-61" href="#__codelineno-16-61"></a>
<a id="__codelineno-16-62" name="__codelineno-16-62" href="#__codelineno-16-62"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-16-63" name="__codelineno-16-63" href="#__codelineno-16-63"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># 通过第一层卷积和 ReLU 激活函数</span>
<a id="__codelineno-16-64" name="__codelineno-16-64" href="#__codelineno-16-64"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 通过最大池化层下采样</span>
<a id="__codelineno-16-65" name="__codelineno-16-65" href="#__codelineno-16-65"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># 通过第二层卷积和 ReLU 激活函数</span>
<a id="__codelineno-16-66" name="__codelineno-16-66" href="#__codelineno-16-66"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 通过最大池化层下采样</span>
<a id="__codelineno-16-67" name="__codelineno-16-67" href="#__codelineno-16-67"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 将特征展平为一维向量</span>
<a id="__codelineno-16-68" name="__codelineno-16-68" href="#__codelineno-16-68"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># 通过全连接层和 ReLU 激活函数</span>
<a id="__codelineno-16-69" name="__codelineno-16-69" href="#__codelineno-16-69"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过全连接层进行分类</span>
<a id="__codelineno-16-70" name="__codelineno-16-70" href="#__codelineno-16-70"></a>        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># 返回最终的输出</span>
<a id="__codelineno-16-71" name="__codelineno-16-71" href="#__codelineno-16-71"></a>
<a id="__codelineno-16-72" name="__codelineno-16-72" href="#__codelineno-16-72"></a><span class="c1"># ResNet 模型</span>
<a id="__codelineno-16-73" name="__codelineno-16-73" href="#__codelineno-16-73"></a><span class="k">class</span><span class="w"> </span><span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-16-74" name="__codelineno-16-74" href="#__codelineno-16-74"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-16-75" name="__codelineno-16-75" href="#__codelineno-16-75"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-16-76" name="__codelineno-16-76" href="#__codelineno-16-76"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># 第一层卷积</span>
<a id="__codelineno-16-77" name="__codelineno-16-77" href="#__codelineno-16-77"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>  <span class="c1"># 批归一化层</span>
<a id="__codelineno-16-78" name="__codelineno-16-78" href="#__codelineno-16-78"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># 第二层卷积</span>
<a id="__codelineno-16-79" name="__codelineno-16-79" href="#__codelineno-16-79"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>  <span class="c1"># 批归一化层</span>
<a id="__codelineno-16-80" name="__codelineno-16-80" href="#__codelineno-16-80"></a>
<a id="__codelineno-16-81" name="__codelineno-16-81" href="#__codelineno-16-81"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>  <span class="c1"># 快捷连接</span>
<a id="__codelineno-16-82" name="__codelineno-16-82" href="#__codelineno-16-82"></a>        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channels</span> <span class="o">!=</span> <span class="n">out_channels</span><span class="p">:</span>  <span class="c1"># 如果步长不为 1 或输入输出通道数不同</span>
<a id="__codelineno-16-83" name="__codelineno-16-83" href="#__codelineno-16-83"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<a id="__codelineno-16-84" name="__codelineno-16-84" href="#__codelineno-16-84"></a>                <span class="c1"># 1x1 卷积调整维度</span>
<a id="__codelineno-16-85" name="__codelineno-16-85" href="#__codelineno-16-85"></a>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>  
<a id="__codelineno-16-86" name="__codelineno-16-86" href="#__codelineno-16-86"></a>                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>  <span class="c1"># 批归一化层</span>
<a id="__codelineno-16-87" name="__codelineno-16-87" href="#__codelineno-16-87"></a>            <span class="p">)</span>
<a id="__codelineno-16-88" name="__codelineno-16-88" href="#__codelineno-16-88"></a>
<a id="__codelineno-16-89" name="__codelineno-16-89" href="#__codelineno-16-89"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-16-90" name="__codelineno-16-90" href="#__codelineno-16-90"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># 通过第一层卷积、批归一化和 ReLU 激活函数</span>
<a id="__codelineno-16-91" name="__codelineno-16-91" href="#__codelineno-16-91"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>  <span class="c1"># 通过第二层卷积和批归一化</span>
<a id="__codelineno-16-92" name="__codelineno-16-92" href="#__codelineno-16-92"></a>        <span class="n">out</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 将快捷连接的结果与卷积结果相加</span>
<a id="__codelineno-16-93" name="__codelineno-16-93" href="#__codelineno-16-93"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># 通过 ReLU 激活函数</span>
<a id="__codelineno-16-94" name="__codelineno-16-94" href="#__codelineno-16-94"></a>        <span class="k">return</span> <span class="n">out</span>  <span class="c1"># 返回最终的输出</span>
<a id="__codelineno-16-95" name="__codelineno-16-95" href="#__codelineno-16-95"></a>
<a id="__codelineno-16-96" name="__codelineno-16-96" href="#__codelineno-16-96"></a><span class="k">class</span><span class="w"> </span><span class="nc">ResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-16-97" name="__codelineno-16-97" href="#__codelineno-16-97"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<a id="__codelineno-16-98" name="__codelineno-16-98" href="#__codelineno-16-98"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">ResNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-16-99" name="__codelineno-16-99" href="#__codelineno-16-99"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># 初始输入通道数</span>
<a id="__codelineno-16-100" name="__codelineno-16-100" href="#__codelineno-16-100"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># 第一层卷积</span>
<a id="__codelineno-16-101" name="__codelineno-16-101" href="#__codelineno-16-101"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>  <span class="c1"># 批归一化层</span>
<a id="__codelineno-16-102" name="__codelineno-16-102" href="#__codelineno-16-102"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 第一层残差块</span>
<a id="__codelineno-16-103" name="__codelineno-16-103" href="#__codelineno-16-103"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 第二层残差块</span>
<a id="__codelineno-16-104" name="__codelineno-16-104" href="#__codelineno-16-104"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 第三层残差块</span>
<a id="__codelineno-16-105" name="__codelineno-16-105" href="#__codelineno-16-105"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 第四层残差块</span>
<a id="__codelineno-16-106" name="__codelineno-16-106" href="#__codelineno-16-106"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>  <span class="c1"># 全连接层，输出大小为 num_classes（10 个类别）</span>
<a id="__codelineno-16-107" name="__codelineno-16-107" href="#__codelineno-16-107"></a>
<a id="__codelineno-16-108" name="__codelineno-16-108" href="#__codelineno-16-108"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
<a id="__codelineno-16-109" name="__codelineno-16-109" href="#__codelineno-16-109"></a>        <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">stride</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 每个残差块的步长</span>
<a id="__codelineno-16-110" name="__codelineno-16-110" href="#__codelineno-16-110"></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 存储残差块的列表</span>
<a id="__codelineno-16-111" name="__codelineno-16-111" href="#__codelineno-16-111"></a>        <span class="k">for</span> <span class="n">stride</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">:</span>
<a id="__codelineno-16-112" name="__codelineno-16-112" href="#__codelineno-16-112"></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">))</span>  <span class="c1"># 添加残差块</span>
<a id="__codelineno-16-113" name="__codelineno-16-113" href="#__codelineno-16-113"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">out_channels</span>  <span class="c1"># 更新输入通道数</span>
<a id="__codelineno-16-114" name="__codelineno-16-114" href="#__codelineno-16-114"></a>        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>  <span class="c1"># 返回一个包含多个残差块的序列</span>
<a id="__codelineno-16-115" name="__codelineno-16-115" href="#__codelineno-16-115"></a>
<a id="__codelineno-16-116" name="__codelineno-16-116" href="#__codelineno-16-116"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-16-117" name="__codelineno-16-117" href="#__codelineno-16-117"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># 通过第一层卷积、批归一化和 ReLU 激活函数</span>
<a id="__codelineno-16-118" name="__codelineno-16-118" href="#__codelineno-16-118"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># 通过第一层残差块</span>
<a id="__codelineno-16-119" name="__codelineno-16-119" href="#__codelineno-16-119"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># 通过第二层残差块</span>
<a id="__codelineno-16-120" name="__codelineno-16-120" href="#__codelineno-16-120"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># 通过第三层残差块</span>
<a id="__codelineno-16-121" name="__codelineno-16-121" href="#__codelineno-16-121"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># 通过第四层残差块</span>
<a id="__codelineno-16-122" name="__codelineno-16-122" href="#__codelineno-16-122"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>  <span class="c1"># 通过平均池化层下采样</span>
<a id="__codelineno-16-123" name="__codelineno-16-123" href="#__codelineno-16-123"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 将特征展平为一维向量</span>
<a id="__codelineno-16-124" name="__codelineno-16-124" href="#__codelineno-16-124"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># 通过全连接层进行分类</span>
<a id="__codelineno-16-125" name="__codelineno-16-125" href="#__codelineno-16-125"></a>        <span class="k">return</span> <span class="n">out</span>  <span class="c1"># 返回最终的输出</span>
<a id="__codelineno-16-126" name="__codelineno-16-126" href="#__codelineno-16-126"></a>
<a id="__codelineno-16-127" name="__codelineno-16-127" href="#__codelineno-16-127"></a><span class="c1"># Vision Transformer (ViT) 模型</span>
<a id="__codelineno-16-128" name="__codelineno-16-128" href="#__codelineno-16-128"></a><span class="k">class</span><span class="w"> </span><span class="nc">PatchEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-16-129" name="__codelineno-16-129" href="#__codelineno-16-129"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
<a id="__codelineno-16-130" name="__codelineno-16-130" href="#__codelineno-16-130"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">PatchEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-16-131" name="__codelineno-16-131" href="#__codelineno-16-131"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span> <span class="o">=</span> <span class="n">img_size</span>  <span class="c1"># 输入图像大小</span>
<a id="__codelineno-16-132" name="__codelineno-16-132" href="#__codelineno-16-132"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>  <span class="c1"># 每个 patch 的大小</span>
<a id="__codelineno-16-133" name="__codelineno-16-133" href="#__codelineno-16-133"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>  <span class="c1"># patch 的数量</span>
<a id="__codelineno-16-134" name="__codelineno-16-134" href="#__codelineno-16-134"></a>        <span class="c1"># 卷积层，将图像分割为 patch 并投影到嵌入空间</span>
<a id="__codelineno-16-135" name="__codelineno-16-135" href="#__codelineno-16-135"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>  
<a id="__codelineno-16-136" name="__codelineno-16-136" href="#__codelineno-16-136"></a>
<a id="__codelineno-16-137" name="__codelineno-16-137" href="#__codelineno-16-137"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-16-138" name="__codelineno-16-138" href="#__codelineno-16-138"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过卷积层将图像分割为 patch</span>
<a id="__codelineno-16-139" name="__codelineno-16-139" href="#__codelineno-16-139"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">'b c h w -&gt; b (h w) c'</span><span class="p">)</span>  <span class="c1"># 使用 rearrange 将 patch 重新排列为序列</span>
<a id="__codelineno-16-140" name="__codelineno-16-140" href="#__codelineno-16-140"></a>        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># 返回最终的输出</span>
<a id="__codelineno-16-141" name="__codelineno-16-141" href="#__codelineno-16-141"></a>
<a id="__codelineno-16-142" name="__codelineno-16-142" href="#__codelineno-16-142"></a><span class="k">class</span><span class="w"> </span><span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-16-143" name="__codelineno-16-143" href="#__codelineno-16-143"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">ff_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<a id="__codelineno-16-144" name="__codelineno-16-144" href="#__codelineno-16-144"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-16-145" name="__codelineno-16-145" href="#__codelineno-16-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># 多头注意力机制</span>
<a id="__codelineno-16-146" name="__codelineno-16-146" href="#__codelineno-16-146"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>  <span class="c1"># 层归一化</span>
<a id="__codelineno-16-147" name="__codelineno-16-147" href="#__codelineno-16-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>  <span class="c1"># 层归一化</span>
<a id="__codelineno-16-148" name="__codelineno-16-148" href="#__codelineno-16-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<a id="__codelineno-16-149" name="__codelineno-16-149" href="#__codelineno-16-149"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">),</span>  <span class="c1"># 前馈神经网络的第一层</span>
<a id="__codelineno-16-150" name="__codelineno-16-150" href="#__codelineno-16-150"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>  <span class="c1"># GELU 激活函数</span>
<a id="__codelineno-16-151" name="__codelineno-16-151" href="#__codelineno-16-151"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ff_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>  <span class="c1"># 前馈神经网络的第二层</span>
<a id="__codelineno-16-152" name="__codelineno-16-152" href="#__codelineno-16-152"></a>        <span class="p">)</span>
<a id="__codelineno-16-153" name="__codelineno-16-153" href="#__codelineno-16-153"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># 随机丢弃部分神经元，防止过拟合</span>
<a id="__codelineno-16-154" name="__codelineno-16-154" href="#__codelineno-16-154"></a>
<a id="__codelineno-16-155" name="__codelineno-16-155" href="#__codelineno-16-155"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-16-156" name="__codelineno-16-156" href="#__codelineno-16-156"></a>        <span class="n">attn_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过多头注意力机制提取特征</span>
<a id="__codelineno-16-157" name="__codelineno-16-157" href="#__codelineno-16-157"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>  <span class="c1"># 通过残差连接和 dropout</span>
<a id="__codelineno-16-158" name="__codelineno-16-158" href="#__codelineno-16-158"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过层归一化</span>
<a id="__codelineno-16-159" name="__codelineno-16-159" href="#__codelineno-16-159"></a>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过前馈神经网络</span>
<a id="__codelineno-16-160" name="__codelineno-16-160" href="#__codelineno-16-160"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">)</span>  <span class="c1"># 通过残差连接和 dropout</span>
<a id="__codelineno-16-161" name="__codelineno-16-161" href="#__codelineno-16-161"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过层归一化</span>
<a id="__codelineno-16-162" name="__codelineno-16-162" href="#__codelineno-16-162"></a>        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># 返回最终的输出</span>
<a id="__codelineno-16-163" name="__codelineno-16-163" href="#__codelineno-16-163"></a>
<a id="__codelineno-16-164" name="__codelineno-16-164" href="#__codelineno-16-164"></a><span class="k">class</span><span class="w"> </span><span class="nc">ViT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-16-165" name="__codelineno-16-165" href="#__codelineno-16-165"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">ff_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<a id="__codelineno-16-166" name="__codelineno-16-166" href="#__codelineno-16-166"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">ViT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-16-167" name="__codelineno-16-167" href="#__codelineno-16-167"></a>        <span class="c1"># Patch Embedding 层</span>
<a id="__codelineno-16-168" name="__codelineno-16-168" href="#__codelineno-16-168"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span> <span class="o">=</span> <span class="n">PatchEmbedding</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>  
<a id="__codelineno-16-169" name="__codelineno-16-169" href="#__codelineno-16-169"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>  <span class="c1"># 位置编码</span>
<a id="__codelineno-16-170" name="__codelineno-16-170" href="#__codelineno-16-170"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>  <span class="c1"># 分类 token</span>
<a id="__codelineno-16-171" name="__codelineno-16-171" href="#__codelineno-16-171"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
<a id="__codelineno-16-172" name="__codelineno-16-172" href="#__codelineno-16-172"></a>            <span class="c1"># 多个 Transformer 编码器层</span>
<a id="__codelineno-16-173" name="__codelineno-16-173" href="#__codelineno-16-173"></a>            <span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>  
<a id="__codelineno-16-174" name="__codelineno-16-174" href="#__codelineno-16-174"></a>        <span class="p">])</span>
<a id="__codelineno-16-175" name="__codelineno-16-175" href="#__codelineno-16-175"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>  <span class="c1"># 层归一化</span>
<a id="__codelineno-16-176" name="__codelineno-16-176" href="#__codelineno-16-176"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>  <span class="c1"># 全连接层，输出大小为 num_classes（10 个类别）</span>
<a id="__codelineno-16-177" name="__codelineno-16-177" href="#__codelineno-16-177"></a>
<a id="__codelineno-16-178" name="__codelineno-16-178" href="#__codelineno-16-178"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-16-179" name="__codelineno-16-179" href="#__codelineno-16-179"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 将图像分割为 patch 并投影到嵌入空间</span>
<a id="__codelineno-16-180" name="__codelineno-16-180" href="#__codelineno-16-180"></a>        <span class="n">cls_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 扩展分类 token</span>
<a id="__codelineno-16-181" name="__codelineno-16-181" href="#__codelineno-16-181"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cls_token</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 将分类 token 和 patch 序列拼接</span>
<a id="__codelineno-16-182" name="__codelineno-16-182" href="#__codelineno-16-182"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span>  <span class="c1"># 添加位置编码</span>
<a id="__codelineno-16-183" name="__codelineno-16-183" href="#__codelineno-16-183"></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">:</span>  <span class="c1"># 通过多个 Transformer 编码器层</span>
<a id="__codelineno-16-184" name="__codelineno-16-184" href="#__codelineno-16-184"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-16-185" name="__codelineno-16-185" href="#__codelineno-16-185"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过层归一化</span>
<a id="__codelineno-16-186" name="__codelineno-16-186" href="#__codelineno-16-186"></a>        <span class="n">cls_output</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># 提取分类 token 的输出</span>
<a id="__codelineno-16-187" name="__codelineno-16-187" href="#__codelineno-16-187"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">cls_output</span><span class="p">)</span>  <span class="c1"># 通过全连接层进行分类</span>
<a id="__codelineno-16-188" name="__codelineno-16-188" href="#__codelineno-16-188"></a>        <span class="k">return</span> <span class="n">out</span>  <span class="c1"># 返回最终的输出</span>
<a id="__codelineno-16-189" name="__codelineno-16-189" href="#__codelineno-16-189"></a>
<a id="__codelineno-16-190" name="__codelineno-16-190" href="#__codelineno-16-190"></a><span class="c1"># 训练函数</span>
<a id="__codelineno-16-191" name="__codelineno-16-191" href="#__codelineno-16-191"></a><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<a id="__codelineno-16-192" name="__codelineno-16-192" href="#__codelineno-16-192"></a>    <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>  <span class="c1"># 存储训练和验证损失</span>
<a id="__codelineno-16-193" name="__codelineno-16-193" href="#__codelineno-16-193"></a>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
<a id="__codelineno-16-194" name="__codelineno-16-194" href="#__codelineno-16-194"></a>        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># 将模型设置为训练模式</span>
<a id="__codelineno-16-195" name="__codelineno-16-195" href="#__codelineno-16-195"></a>        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># 累计每个 epoch 的损失</span>
<a id="__codelineno-16-196" name="__codelineno-16-196" href="#__codelineno-16-196"></a>        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
<a id="__codelineno-16-197" name="__codelineno-16-197" href="#__codelineno-16-197"></a>            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 将数据移动到设备（GPU 或 CPU）</span>
<a id="__codelineno-16-198" name="__codelineno-16-198" href="#__codelineno-16-198"></a>            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># 清空梯度</span>
<a id="__codelineno-16-199" name="__codelineno-16-199" href="#__codelineno-16-199"></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># 前向传播，计算输出</span>
<a id="__codelineno-16-200" name="__codelineno-16-200" href="#__codelineno-16-200"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># 计算损失</span>
<a id="__codelineno-16-201" name="__codelineno-16-201" href="#__codelineno-16-201"></a>            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># 反向传播，计算梯度</span>
<a id="__codelineno-16-202" name="__codelineno-16-202" href="#__codelineno-16-202"></a>            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># 更新模型参数</span>
<a id="__codelineno-16-203" name="__codelineno-16-203" href="#__codelineno-16-203"></a>            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># 累计损失</span>
<a id="__codelineno-16-204" name="__codelineno-16-204" href="#__codelineno-16-204"></a>        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>  <span class="c1"># 记录每个 epoch 的训练损失</span>
<a id="__codelineno-16-205" name="__codelineno-16-205" href="#__codelineno-16-205"></a>
<a id="__codelineno-16-206" name="__codelineno-16-206" href="#__codelineno-16-206"></a>        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
<a id="__codelineno-16-207" name="__codelineno-16-207" href="#__codelineno-16-207"></a>        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># 累计验证集的损失</span>
<a id="__codelineno-16-208" name="__codelineno-16-208" href="#__codelineno-16-208"></a>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># 不计算梯度，节省内存</span>
<a id="__codelineno-16-209" name="__codelineno-16-209" href="#__codelineno-16-209"></a>            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
<a id="__codelineno-16-210" name="__codelineno-16-210" href="#__codelineno-16-210"></a>                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 将数据移动到设备（GPU 或 CPU）</span>
<a id="__codelineno-16-211" name="__codelineno-16-211" href="#__codelineno-16-211"></a>                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># 前向传播，计算输出</span>
<a id="__codelineno-16-212" name="__codelineno-16-212" href="#__codelineno-16-212"></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># 计算损失</span>
<a id="__codelineno-16-213" name="__codelineno-16-213" href="#__codelineno-16-213"></a>                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># 累计损失</span>
<a id="__codelineno-16-214" name="__codelineno-16-214" href="#__codelineno-16-214"></a>        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))</span>  <span class="c1"># 记录每个 epoch 的验证损失</span>
<a id="__codelineno-16-215" name="__codelineno-16-215" href="#__codelineno-16-215"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  <span class="c1"># 打印训练和验证损失</span>
<a id="__codelineno-16-216" name="__codelineno-16-216" href="#__codelineno-16-216"></a>    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span>  <span class="c1"># 返回训练和验证损失列表</span>
<a id="__codelineno-16-217" name="__codelineno-16-217" href="#__codelineno-16-217"></a>
<a id="__codelineno-16-218" name="__codelineno-16-218" href="#__codelineno-16-218"></a><span class="c1"># 计算参数量</span>
<a id="__codelineno-16-219" name="__codelineno-16-219" href="#__codelineno-16-219"></a><span class="k">def</span><span class="w"> </span><span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<a id="__codelineno-16-220" name="__codelineno-16-220" href="#__codelineno-16-220"></a>    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>  <span class="c1"># 计算模型的参数量</span>
<a id="__codelineno-16-221" name="__codelineno-16-221" href="#__codelineno-16-221"></a>
<a id="__codelineno-16-222" name="__codelineno-16-222" href="#__codelineno-16-222"></a><span class="c1"># 计算模型大小</span>
<a id="__codelineno-16-223" name="__codelineno-16-223" href="#__codelineno-16-223"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<a id="__codelineno-16-224" name="__codelineno-16-224" href="#__codelineno-16-224"></a>    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>  <span class="c1"># 计算模型的大小（以字节为单位）</span>
<a id="__codelineno-16-225" name="__codelineno-16-225" href="#__codelineno-16-225"></a>
<a id="__codelineno-16-226" name="__codelineno-16-226" href="#__codelineno-16-226"></a><span class="c1"># 计算平均推理时间 per sample</span>
<a id="__codelineno-16-227" name="__codelineno-16-227" href="#__codelineno-16-227"></a><span class="k">def</span><span class="w"> </span><span class="nf">measure_inference_time</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
<a id="__codelineno-16-228" name="__codelineno-16-228" href="#__codelineno-16-228"></a>    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
<a id="__codelineno-16-229" name="__codelineno-16-229" href="#__codelineno-16-229"></a>    <span class="n">total_time</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># 累计推理时间</span>
<a id="__codelineno-16-230" name="__codelineno-16-230" href="#__codelineno-16-230"></a>    <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 累计样本数量</span>
<a id="__codelineno-16-231" name="__codelineno-16-231" href="#__codelineno-16-231"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># 不计算梯度，节省内存</span>
<a id="__codelineno-16-232" name="__codelineno-16-232" href="#__codelineno-16-232"></a>        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
<a id="__codelineno-16-233" name="__codelineno-16-233" href="#__codelineno-16-233"></a>            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 将数据移动到设备（GPU 或 CPU）</span>
<a id="__codelineno-16-234" name="__codelineno-16-234" href="#__codelineno-16-234"></a>            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># 记录开始时间</span>
<a id="__codelineno-16-235" name="__codelineno-16-235" href="#__codelineno-16-235"></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># 前向传播，计算输出</span>
<a id="__codelineno-16-236" name="__codelineno-16-236" href="#__codelineno-16-236"></a>            <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># 记录结束时间</span>
<a id="__codelineno-16-237" name="__codelineno-16-237" href="#__codelineno-16-237"></a>            <span class="n">total_time</span> <span class="o">+=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># 累计推理时间</span>
<a id="__codelineno-16-238" name="__codelineno-16-238" href="#__codelineno-16-238"></a>            <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 累计样本数量</span>
<a id="__codelineno-16-239" name="__codelineno-16-239" href="#__codelineno-16-239"></a>    <span class="n">avg_time_per_sample</span> <span class="o">=</span> <span class="n">total_time</span> <span class="o">/</span> <span class="n">num_samples</span>  <span class="c1"># 计算每个样本的平均推理时间</span>
<a id="__codelineno-16-240" name="__codelineno-16-240" href="#__codelineno-16-240"></a>    <span class="k">return</span> <span class="n">avg_time_per_sample</span>  <span class="c1"># 返回平均推理时间</span>
<a id="__codelineno-16-241" name="__codelineno-16-241" href="#__codelineno-16-241"></a>
<a id="__codelineno-16-242" name="__codelineno-16-242" href="#__codelineno-16-242"></a><span class="c1"># 评估测试集性能</span>
<a id="__codelineno-16-243" name="__codelineno-16-243" href="#__codelineno-16-243"></a><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_on_test_set</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
<a id="__codelineno-16-244" name="__codelineno-16-244" href="#__codelineno-16-244"></a>    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
<a id="__codelineno-16-245" name="__codelineno-16-245" href="#__codelineno-16-245"></a>    <span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># 累计测试集的损失</span>
<a id="__codelineno-16-246" name="__codelineno-16-246" href="#__codelineno-16-246"></a>    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 累计正确预测的数量</span>
<a id="__codelineno-16-247" name="__codelineno-16-247" href="#__codelineno-16-247"></a>    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 累计样本数量</span>
<a id="__codelineno-16-248" name="__codelineno-16-248" href="#__codelineno-16-248"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># 不计算梯度，节省内存</span>
<a id="__codelineno-16-249" name="__codelineno-16-249" href="#__codelineno-16-249"></a>        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
<a id="__codelineno-16-250" name="__codelineno-16-250" href="#__codelineno-16-250"></a>            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 将数据移动到设备（GPU 或 CPU）</span>
<a id="__codelineno-16-251" name="__codelineno-16-251" href="#__codelineno-16-251"></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># 前向传播，计算输出</span>
<a id="__codelineno-16-252" name="__codelineno-16-252" href="#__codelineno-16-252"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># 计算损失</span>
<a id="__codelineno-16-253" name="__codelineno-16-253" href="#__codelineno-16-253"></a>            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># 累计损失</span>
<a id="__codelineno-16-254" name="__codelineno-16-254" href="#__codelineno-16-254"></a>            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 获取预测结果</span>
<a id="__codelineno-16-255" name="__codelineno-16-255" href="#__codelineno-16-255"></a>            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 累计样本数量</span>
<a id="__codelineno-16-256" name="__codelineno-16-256" href="#__codelineno-16-256"></a>            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># 累计正确预测的数量</span>
<a id="__codelineno-16-257" name="__codelineno-16-257" href="#__codelineno-16-257"></a>    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>  <span class="c1"># 计算平均测试损失</span>
<a id="__codelineno-16-258" name="__codelineno-16-258" href="#__codelineno-16-258"></a>    <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>  <span class="c1"># 计算测试准确率</span>
<a id="__codelineno-16-259" name="__codelineno-16-259" href="#__codelineno-16-259"></a>    <span class="k">return</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span>  <span class="c1"># 返回测试损失和准确率</span>
<a id="__codelineno-16-260" name="__codelineno-16-260" href="#__codelineno-16-260"></a>
<a id="__codelineno-16-261" name="__codelineno-16-261" href="#__codelineno-16-261"></a><span class="c1"># 定义不同的参数组合</span>
<a id="__codelineno-16-262" name="__codelineno-16-262" href="#__codelineno-16-262"></a><span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>  <span class="c1"># 学习率列表</span>
<a id="__codelineno-16-263" name="__codelineno-16-263" href="#__codelineno-16-263"></a><span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">]</span>  <span class="c1"># 优化器列表</span>
<a id="__codelineno-16-264" name="__codelineno-16-264" href="#__codelineno-16-264"></a><span class="n">activation_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">]</span>  <span class="c1"># 激活函数列表</span>
<a id="__codelineno-16-265" name="__codelineno-16-265" href="#__codelineno-16-265"></a>
<a id="__codelineno-16-266" name="__codelineno-16-266" href="#__codelineno-16-266"></a><span class="c1"># 训练和评估不同参数组合</span>
<a id="__codelineno-16-267" name="__codelineno-16-267" href="#__codelineno-16-267"></a><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># 存储不同参数组合的结果</span>
<a id="__codelineno-16-268" name="__codelineno-16-268" href="#__codelineno-16-268"></a><span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
<a id="__codelineno-16-269" name="__codelineno-16-269" href="#__codelineno-16-269"></a>    <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
<a id="__codelineno-16-270" name="__codelineno-16-270" href="#__codelineno-16-270"></a>        <span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">activation_functions</span><span class="p">:</span>
<a id="__codelineno-16-271" name="__codelineno-16-271" href="#__codelineno-16-271"></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 初始化模型</span>
<a id="__codelineno-16-272" name="__codelineno-16-272" href="#__codelineno-16-272"></a>            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>  <span class="c1"># 初始化优化器</span>
<a id="__codelineno-16-273" name="__codelineno-16-273" href="#__codelineno-16-273"></a>            <span class="c1"># 打印当前参数组合</span>
<a id="__codelineno-16-274" name="__codelineno-16-274" href="#__codelineno-16-274"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training with lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">, optimizer=</span><span class="si">{</span><span class="n">opt</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, activation=</span><span class="si">{</span><span class="n">activation</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> 
<a id="__codelineno-16-275" name="__codelineno-16-275" href="#__codelineno-16-275"></a>            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># 记录开始时间</span>
<a id="__codelineno-16-276" name="__codelineno-16-276" href="#__codelineno-16-276"></a>            <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># 训练模型</span>
<a id="__codelineno-16-277" name="__codelineno-16-277" href="#__codelineno-16-277"></a>            <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># 计算训练时间</span>
<a id="__codelineno-16-278" name="__codelineno-16-278" href="#__codelineno-16-278"></a>            <span class="c1"># 评估测试集性能</span>
<a id="__codelineno-16-279" name="__codelineno-16-279" href="#__codelineno-16-279"></a>            <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">evaluate_on_test_set</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">())</span> 
<a id="__codelineno-16-280" name="__codelineno-16-280" href="#__codelineno-16-280"></a>            <span class="n">avg_inference_time</span> <span class="o">=</span> <span class="n">measure_inference_time</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>  <span class="c1"># 计算平均推理时间</span>
<a id="__codelineno-16-281" name="__codelineno-16-281" href="#__codelineno-16-281"></a>            <span class="n">results</span><span class="p">[(</span><span class="n">lr</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">activation</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># 存储结果</span>
<a id="__codelineno-16-282" name="__codelineno-16-282" href="#__codelineno-16-282"></a>                <span class="s1">'train_losses'</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
<a id="__codelineno-16-283" name="__codelineno-16-283" href="#__codelineno-16-283"></a>                <span class="s1">'val_losses'</span><span class="p">:</span> <span class="n">val_losses</span><span class="p">,</span>
<a id="__codelineno-16-284" name="__codelineno-16-284" href="#__codelineno-16-284"></a>                <span class="s1">'training_time'</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
<a id="__codelineno-16-285" name="__codelineno-16-285" href="#__codelineno-16-285"></a>                <span class="s1">'test_loss'</span><span class="p">:</span> <span class="n">test_loss</span><span class="p">,</span>
<a id="__codelineno-16-286" name="__codelineno-16-286" href="#__codelineno-16-286"></a>                <span class="s1">'test_accuracy'</span><span class="p">:</span> <span class="n">test_accuracy</span><span class="p">,</span>
<a id="__codelineno-16-287" name="__codelineno-16-287" href="#__codelineno-16-287"></a>                <span class="s1">'parameters'</span><span class="p">:</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-16-288" name="__codelineno-16-288" href="#__codelineno-16-288"></a>                <span class="s1">'model_size'</span><span class="p">:</span> <span class="n">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-16-289" name="__codelineno-16-289" href="#__codelineno-16-289"></a>                <span class="s1">'avg_inference_time'</span><span class="p">:</span> <span class="n">avg_inference_time</span>
<a id="__codelineno-16-290" name="__codelineno-16-290" href="#__codelineno-16-290"></a>            <span class="p">}</span>
<a id="__codelineno-16-291" name="__codelineno-16-291" href="#__codelineno-16-291"></a>
<a id="__codelineno-16-292" name="__codelineno-16-292" href="#__codelineno-16-292"></a><span class="c1"># 绘制所有 Loss 曲线</span>
<a id="__codelineno-16-293" name="__codelineno-16-293" href="#__codelineno-16-293"></a><span class="k">def</span><span class="w"> </span><span class="nf">plot_all_loss_curves</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
<a id="__codelineno-16-294" name="__codelineno-16-294" href="#__codelineno-16-294"></a>    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>  <span class="c1"># 创建一个大图，包含 3 行 1 列的子图</span>
<a id="__codelineno-16-295" name="__codelineno-16-295" href="#__codelineno-16-295"></a>
<a id="__codelineno-16-296" name="__codelineno-16-296" href="#__codelineno-16-296"></a>    <span class="c1"># 绘制不同学习率的 Loss 曲线</span>
<a id="__codelineno-16-297" name="__codelineno-16-297" href="#__codelineno-16-297"></a>    <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
<a id="__codelineno-16-298" name="__codelineno-16-298" href="#__codelineno-16-298"></a>        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">,</span> <span class="s1">'relu'</span><span class="p">)</span>
<a id="__codelineno-16-299" name="__codelineno-16-299" href="#__codelineno-16-299"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<a id="__codelineno-16-300" name="__codelineno-16-300" href="#__codelineno-16-300"></a>            <span class="n">train_losses</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'train_losses'</span><span class="p">]</span>
<a id="__codelineno-16-301" name="__codelineno-16-301" href="#__codelineno-16-301"></a>            <span class="n">val_losses</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'val_losses'</span><span class="p">]</span>
<a id="__codelineno-16-302" name="__codelineno-16-302" href="#__codelineno-16-302"></a>            <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Train Loss (lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>  <span class="c1"># 绘制训练损失曲线</span>
<a id="__codelineno-16-303" name="__codelineno-16-303" href="#__codelineno-16-303"></a>            <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Val Loss (lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>  <span class="c1"># 绘制验证损失曲线</span>
<a id="__codelineno-16-304" name="__codelineno-16-304" href="#__codelineno-16-304"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Loss Curves for Different Learning Rates (Adam, ReLU)'</span><span class="p">)</span>  <span class="c1"># 设置标题</span>
<a id="__codelineno-16-305" name="__codelineno-16-305" href="#__codelineno-16-305"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>  <span class="c1"># 设置 x 轴标签</span>
<a id="__codelineno-16-306" name="__codelineno-16-306" href="#__codelineno-16-306"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>  <span class="c1"># 设置 y 轴标签</span>
<a id="__codelineno-16-307" name="__codelineno-16-307" href="#__codelineno-16-307"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># 显示图例</span>
<a id="__codelineno-16-308" name="__codelineno-16-308" href="#__codelineno-16-308"></a>
<a id="__codelineno-16-309" name="__codelineno-16-309" href="#__codelineno-16-309"></a>    <span class="c1"># 绘制不同优化器的 Loss 曲线</span>
<a id="__codelineno-16-310" name="__codelineno-16-310" href="#__codelineno-16-310"></a>    <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
<a id="__codelineno-16-311" name="__codelineno-16-311" href="#__codelineno-16-311"></a>        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">'relu'</span><span class="p">)</span>
<a id="__codelineno-16-312" name="__codelineno-16-312" href="#__codelineno-16-312"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<a id="__codelineno-16-313" name="__codelineno-16-313" href="#__codelineno-16-313"></a>            <span class="n">train_losses</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'train_losses'</span><span class="p">]</span>
<a id="__codelineno-16-314" name="__codelineno-16-314" href="#__codelineno-16-314"></a>            <span class="n">val_losses</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'val_losses'</span><span class="p">]</span>
<a id="__codelineno-16-315" name="__codelineno-16-315" href="#__codelineno-16-315"></a>            <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Train Loss (optimizer=</span><span class="si">{</span><span class="n">opt</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>  <span class="c1"># 绘制训练损失曲线</span>
<a id="__codelineno-16-316" name="__codelineno-16-316" href="#__codelineno-16-316"></a>            <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Val Loss (optimizer=</span><span class="si">{</span><span class="n">opt</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>  <span class="c1"># 绘制验证损失曲线</span>
<a id="__codelineno-16-317" name="__codelineno-16-317" href="#__codelineno-16-317"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Loss Curves for Different Optimizers (lr=0.001, ReLU)'</span><span class="p">)</span>  <span class="c1"># 设置标题</span>
<a id="__codelineno-16-318" name="__codelineno-16-318" href="#__codelineno-16-318"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>  <span class="c1"># 设置 x 轴标签</span>
<a id="__codelineno-16-319" name="__codelineno-16-319" href="#__codelineno-16-319"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>  <span class="c1"># 设置 y 轴标签</span>
<a id="__codelineno-16-320" name="__codelineno-16-320" href="#__codelineno-16-320"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># 显示图例</span>
<a id="__codelineno-16-321" name="__codelineno-16-321" href="#__codelineno-16-321"></a>
<a id="__codelineno-16-322" name="__codelineno-16-322" href="#__codelineno-16-322"></a>    <span class="c1"># 绘制不同激活函数的 Loss 曲线</span>
<a id="__codelineno-16-323" name="__codelineno-16-323" href="#__codelineno-16-323"></a>    <span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">activation_functions</span><span class="p">:</span>
<a id="__codelineno-16-324" name="__codelineno-16-324" href="#__codelineno-16-324"></a>        <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">,</span> <span class="n">activation</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<a id="__codelineno-16-325" name="__codelineno-16-325" href="#__codelineno-16-325"></a>        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<a id="__codelineno-16-326" name="__codelineno-16-326" href="#__codelineno-16-326"></a>            <span class="n">train_losses</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'train_losses'</span><span class="p">]</span>
<a id="__codelineno-16-327" name="__codelineno-16-327" href="#__codelineno-16-327"></a>            <span class="n">val_losses</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">'val_losses'</span><span class="p">]</span>
<a id="__codelineno-16-328" name="__codelineno-16-328" href="#__codelineno-16-328"></a>            <span class="c1"># 绘制训练损失曲线</span>
<a id="__codelineno-16-329" name="__codelineno-16-329" href="#__codelineno-16-329"></a>            <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Train Loss (activation=</span><span class="si">{</span><span class="n">activation</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>  
<a id="__codelineno-16-330" name="__codelineno-16-330" href="#__codelineno-16-330"></a>            <span class="c1"># 绘制验证损失曲线</span>
<a id="__codelineno-16-331" name="__codelineno-16-331" href="#__codelineno-16-331"></a>            <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Val Loss (activation=</span><span class="si">{</span><span class="n">activation</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>  
<a id="__codelineno-16-332" name="__codelineno-16-332" href="#__codelineno-16-332"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Loss Curves for Different Activation Functions (lr=0.001, Adam)'</span><span class="p">)</span>  <span class="c1"># 设置标题</span>
<a id="__codelineno-16-333" name="__codelineno-16-333" href="#__codelineno-16-333"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>  <span class="c1"># 设置 x 轴标签</span>
<a id="__codelineno-16-334" name="__codelineno-16-334" href="#__codelineno-16-334"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>  <span class="c1"># 设置 y 轴标签</span>
<a id="__codelineno-16-335" name="__codelineno-16-335" href="#__codelineno-16-335"></a>    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># 显示图例</span>
<a id="__codelineno-16-336" name="__codelineno-16-336" href="#__codelineno-16-336"></a>
<a id="__codelineno-16-337" name="__codelineno-16-337" href="#__codelineno-16-337"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>  <span class="c1"># 调整布局，避免重叠</span>
<a id="__codelineno-16-338" name="__codelineno-16-338" href="#__codelineno-16-338"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># 显示绘制的图表</span>
<a id="__codelineno-16-339" name="__codelineno-16-339" href="#__codelineno-16-339"></a>
<a id="__codelineno-16-340" name="__codelineno-16-340" href="#__codelineno-16-340"></a><span class="c1"># 调用函数绘制所有 Loss 曲线</span>
<a id="__codelineno-16-341" name="__codelineno-16-341" href="#__codelineno-16-341"></a><span class="n">plot_all_loss_curves</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<a id="__codelineno-16-342" name="__codelineno-16-342" href="#__codelineno-16-342"></a>
<a id="__codelineno-16-343" name="__codelineno-16-343" href="#__codelineno-16-343"></a><span class="c1"># 计算复杂度分析</span>
<a id="__codelineno-16-344" name="__codelineno-16-344" href="#__codelineno-16-344"></a><span class="k">for</span> <span class="n">params</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-16-345" name="__codelineno-16-345" href="#__codelineno-16-345"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Params: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  <span class="c1"># 打印当前参数组合</span>
<a id="__codelineno-16-346" name="__codelineno-16-346" href="#__codelineno-16-346"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Training Time: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'training_time'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>  <span class="c1"># 打印训练时间</span>
<a id="__codelineno-16-347" name="__codelineno-16-347" href="#__codelineno-16-347"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Parameters: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'parameters'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  <span class="c1"># 打印参数量</span>
<a id="__codelineno-16-348" name="__codelineno-16-348" href="#__codelineno-16-348"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Model Size: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'model_size'</span><span class="p">]</span><span class="si">}</span><span class="s2"> bytes"</span><span class="p">)</span>  <span class="c1"># 打印模型大小</span>
<a id="__codelineno-16-349" name="__codelineno-16-349" href="#__codelineno-16-349"></a>    <span class="c1"># 打印平均推理时间</span>
<a id="__codelineno-16-350" name="__codelineno-16-350" href="#__codelineno-16-350"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Average Inference Time per Sample: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'avg_inference_time'</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span> 
<a id="__codelineno-16-351" name="__codelineno-16-351" href="#__codelineno-16-351"></a>    <span class="c1"># 打印测试损失和准确率</span>
<a id="__codelineno-16-352" name="__codelineno-16-352" href="#__codelineno-16-352"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test Loss: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'test_loss'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test Accuracy: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'test_accuracy'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  
<a id="__codelineno-16-353" name="__codelineno-16-353" href="#__codelineno-16-353"></a>    <span class="nb">print</span><span class="p">()</span>
<a id="__codelineno-16-354" name="__codelineno-16-354" href="#__codelineno-16-354"></a>
<a id="__codelineno-16-355" name="__codelineno-16-355" href="#__codelineno-16-355"></a><span class="c1"># 定义模型列表</span>
<a id="__codelineno-16-356" name="__codelineno-16-356" href="#__codelineno-16-356"></a><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-16-357" name="__codelineno-16-357" href="#__codelineno-16-357"></a>    <span class="s1">'CNN'</span><span class="p">:</span> <span class="n">CNN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>  <span class="c1"># CNN 模型</span>
<a id="__codelineno-16-358" name="__codelineno-16-358" href="#__codelineno-16-358"></a>    <span class="s1">'ResNet'</span><span class="p">:</span> <span class="n">ResNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>  <span class="c1"># ResNet 模型</span>
<a id="__codelineno-16-359" name="__codelineno-16-359" href="#__codelineno-16-359"></a>    <span class="s1">'ViT'</span><span class="p">:</span> <span class="n">ViT</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># ViT 模型</span>
<a id="__codelineno-16-360" name="__codelineno-16-360" href="#__codelineno-16-360"></a><span class="p">}</span>
<a id="__codelineno-16-361" name="__codelineno-16-361" href="#__codelineno-16-361"></a>
<a id="__codelineno-16-362" name="__codelineno-16-362" href="#__codelineno-16-362"></a><span class="c1"># 训练和评估每个模型</span>
<a id="__codelineno-16-363" name="__codelineno-16-363" href="#__codelineno-16-363"></a><span class="n">model_results</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># 存储每个模型的结果</span>
<a id="__codelineno-16-364" name="__codelineno-16-364" href="#__codelineno-16-364"></a><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-16-365" name="__codelineno-16-365" href="#__codelineno-16-365"></a>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># 初始化优化器</span>
<a id="__codelineno-16-366" name="__codelineno-16-366" href="#__codelineno-16-366"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> model"</span><span class="p">)</span>  <span class="c1"># 打印当前模型名称</span>
<a id="__codelineno-16-367" name="__codelineno-16-367" href="#__codelineno-16-367"></a>    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># 记录开始时间</span>
<a id="__codelineno-16-368" name="__codelineno-16-368" href="#__codelineno-16-368"></a>    <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># 训练模型</span>
<a id="__codelineno-16-369" name="__codelineno-16-369" href="#__codelineno-16-369"></a>    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># 计算训练时间</span>
<a id="__codelineno-16-370" name="__codelineno-16-370" href="#__codelineno-16-370"></a>    <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">evaluate_on_test_set</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">())</span>  <span class="c1"># 评估测试集性能</span>
<a id="__codelineno-16-371" name="__codelineno-16-371" href="#__codelineno-16-371"></a>    <span class="n">avg_inference_time</span> <span class="o">=</span> <span class="n">measure_inference_time</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>  <span class="c1"># 计算平均推理时间</span>
<a id="__codelineno-16-372" name="__codelineno-16-372" href="#__codelineno-16-372"></a>    <span class="n">model_results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># 存储结果</span>
<a id="__codelineno-16-373" name="__codelineno-16-373" href="#__codelineno-16-373"></a>        <span class="s1">'train_losses'</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
<a id="__codelineno-16-374" name="__codelineno-16-374" href="#__codelineno-16-374"></a>        <span class="s1">'val_losses'</span><span class="p">:</span> <span class="n">val_losses</span><span class="p">,</span>
<a id="__codelineno-16-375" name="__codelineno-16-375" href="#__codelineno-16-375"></a>        <span class="s1">'training_time'</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
<a id="__codelineno-16-376" name="__codelineno-16-376" href="#__codelineno-16-376"></a>        <span class="s1">'test_loss'</span><span class="p">:</span> <span class="n">test_loss</span><span class="p">,</span>
<a id="__codelineno-16-377" name="__codelineno-16-377" href="#__codelineno-16-377"></a>        <span class="s1">'test_accuracy'</span><span class="p">:</span> <span class="n">test_accuracy</span><span class="p">,</span>
<a id="__codelineno-16-378" name="__codelineno-16-378" href="#__codelineno-16-378"></a>        <span class="s1">'parameters'</span><span class="p">:</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-16-379" name="__codelineno-16-379" href="#__codelineno-16-379"></a>        <span class="s1">'model_size'</span><span class="p">:</span> <span class="n">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-16-380" name="__codelineno-16-380" href="#__codelineno-16-380"></a>        <span class="s1">'avg_inference_time'</span><span class="p">:</span> <span class="n">avg_inference_time</span>
<a id="__codelineno-16-381" name="__codelineno-16-381" href="#__codelineno-16-381"></a>    <span class="p">}</span>
<a id="__codelineno-16-382" name="__codelineno-16-382" href="#__codelineno-16-382"></a>
<a id="__codelineno-16-383" name="__codelineno-16-383" href="#__codelineno-16-383"></a><span class="c1"># 绘制对比图</span>
<a id="__codelineno-16-384" name="__codelineno-16-384" href="#__codelineno-16-384"></a><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">model_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-16-385" name="__codelineno-16-385" href="#__codelineno-16-385"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">'train_losses'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1"> Training Loss'</span><span class="p">)</span>  <span class="c1"># 绘制训练损失曲线</span>
<a id="__codelineno-16-386" name="__codelineno-16-386" href="#__codelineno-16-386"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">'val_losses'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1"> Validation Loss'</span><span class="p">)</span>  <span class="c1"># 绘制验证损失曲线</span>
<a id="__codelineno-16-387" name="__codelineno-16-387" href="#__codelineno-16-387"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>  <span class="c1"># 设置 x 轴标签</span>
<a id="__codelineno-16-388" name="__codelineno-16-388" href="#__codelineno-16-388"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>  <span class="c1"># 设置 y 轴标签</span>
<a id="__codelineno-16-389" name="__codelineno-16-389" href="#__codelineno-16-389"></a><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>  <span class="c1"># 显示图例</span>
<a id="__codelineno-16-390" name="__codelineno-16-390" href="#__codelineno-16-390"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># 显示绘制的图表</span>
<a id="__codelineno-16-391" name="__codelineno-16-391" href="#__codelineno-16-391"></a>
<a id="__codelineno-16-392" name="__codelineno-16-392" href="#__codelineno-16-392"></a><span class="c1"># 计算复杂度分析</span>
<a id="__codelineno-16-393" name="__codelineno-16-393" href="#__codelineno-16-393"></a><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">model_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-16-394" name="__codelineno-16-394" href="#__codelineno-16-394"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> - Parameters: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'parameters'</span><span class="p">]</span><span class="si">}</span><span class="s2">, Model Size: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'model_size'</span><span class="p">]</span><span class="si">}</span><span class="s2"> bytes, Training Time: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'training_time'</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds, Average Inference Time per Sample: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'avg_inference_time'</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> seconds, Test Loss: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'test_loss'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test Accuracy: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">'test_accuracy'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>  <span class="c1"># 打印复杂度分析结果</span>
</code></pre></div>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>结构图绘制工具：<a href="http://alexlenail.me/NN-SVG/LeNet.html">http://alexlenail.me/NN-SVG/LeNet.html</a> <a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:2">
<p><a href="https://github.com/junaidaliop/pytorch-fashionMNIST-tutorial">https://github.com/junaidaliop/pytorch-fashionMNIST-tutorial</a> <a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
</ol>
</div></div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="2025年2月13日 19:25:02">2025-02-13 19:25:02</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime" title="2025年2月13日 19:25:02">2025-02-13 19:25:02</span>
  </span>

    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Looking for your feedback!
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              
              
                
                
              
              O(∩_∩)O谢谢啦~
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              
              
                
                
              
              嘿呀嘿呀，努力搬砖...
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../bookReport/%E3%80%8A%E8%BF%9C%E5%A4%A7%E5%89%8D%E7%A8%8B%E3%80%8B%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 《远大前程》阅读报告">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6 18V6h2v12zm3.5-6L18 6v12z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                《远大前程》阅读报告
              </div>
            </div>
          </a>
        
        
          
          <a href="../../ROCOS/" class="md-footer__link md-footer__link--next" aria-label="下一页: rocos 菜鸟入门">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                rocos 菜鸟入门
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16 18h2V6h-2M6 18l8.5-6L6 6z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024-2025 | powered by dixiLOG | All rights reserved.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/dixiLOG" target="_blank" rel="noopener" title="我滴GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:<huang1444127184@gmail.com>" target="_blank" rel="noopener" title="我滴邮箱 | huang1444127184@gmail.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M24 5.457v13.909c0 .904-.732 1.636-1.636 1.636h-3.819V11.73L12 16.64l-6.545-4.91v9.273H1.636A1.636 1.636 0 0 1 0 19.366V5.457c0-2.023 2.309-3.178 3.927-1.964L5.455 4.64 12 9.548l6.545-4.91 1.528-1.145C21.69 2.28 24 3.434 24 5.457"/></svg>
    </a>
  
    
    
    
    
    <a href="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/20250311085545.png" target="_blank" rel="noopener" title="我滴QQ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704"/></svg>
    </a>
  
    
    
    
    
    <a href="https://cdn.jsdelivr.net/gh/dixiLOG/blogStatic/20250311085606.png" target="_blank" rel="noopener" title="我滴微信" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.691 2.188C3.891 2.188 0 5.476 0 9.53c0 2.212 1.17 4.203 3.002 5.55a.59.59 0 0 1 .213.665l-.39 1.48c-.019.07-.048.141-.048.213 0 .163.13.295.29.295a.33.33 0 0 0 .167-.054l1.903-1.114a.86.86 0 0 1 .717-.098 10.2 10.2 0 0 0 2.837.403c.276 0 .543-.027.811-.05-.857-2.578.157-4.972 1.932-6.446 1.703-1.415 3.882-1.98 5.853-1.838-.576-3.583-4.196-6.348-8.596-6.348M5.785 5.991c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178A1.17 1.17 0 0 1 4.623 7.17c0-.651.52-1.18 1.162-1.18zm5.813 0c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178 1.17 1.17 0 0 1-1.162-1.178c0-.651.52-1.18 1.162-1.18m5.34 2.867c-1.797-.052-3.746.512-5.28 1.786-1.72 1.428-2.687 3.72-1.78 6.22.942 2.453 3.666 4.229 6.884 4.229.826 0 1.622-.12 2.361-.336a.72.72 0 0 1 .598.082l1.584.926a.3.3 0 0 0 .14.047c.134 0 .24-.111.24-.247 0-.06-.023-.12-.038-.177l-.327-1.233a.6.6 0 0 1-.023-.156.49.49 0 0 1 .201-.398C23.024 18.48 24 16.82 24 14.98c0-3.21-2.931-5.837-6.656-6.088V8.89c-.135-.01-.27-.027-.407-.03zm-2.53 3.274c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.97-.982zm4.844 0c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.969-.982"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tabs", "navigation.tracking", "navigation.footer", "search.highlight", "navigation.indexes", "navigation.prune", "toc.follow", "navigation.top", "content.code.annotate", "content.tooltips", "search.suggest", "search.share", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="https://imgbb.com/upload.js"></script>
      
        <script src="../../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>